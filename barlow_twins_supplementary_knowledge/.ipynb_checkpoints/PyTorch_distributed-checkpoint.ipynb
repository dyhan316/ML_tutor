{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d286587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0905255e",
   "metadata": {},
   "source": [
    "look at https://www.youtube.com/watch?v=3XUG7cjte2U&t=1832s\n",
    "\n",
    "https://www.youtube.com/watch?v=TibQO_xv1zc&t=2128s  ==> better\n",
    "\n",
    "https://www.youtube.com/watch?v=RQfK_ViGzH0&t=110s ==> 이거는 어려워서 필요없을수도\n",
    "\n",
    "\n",
    "제일 중요한 tutorial (이것보고 밑에 작성) : \n",
    "https://tutorials.pytorch.kr/beginner/dist_overview.html\n",
    "\n",
    "(github version of this : https://github.com/pytorch/tutorials/blob/master/beginner_source/dist_overview.rst) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b97bfba",
   "metadata": {},
   "source": [
    "# Prelude. Basic Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0f4b82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.device_count() #see how many gpus I can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef173b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c9d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3071b99",
   "metadata": {},
   "source": [
    "# 그냥 https://theaisummer.com/distributed-training-pytorch/ 여기보고 따라하기!! 여기서 너무 설명 잘해줘서. 이걸로 1. 2.둘다 하면 될듯?\n",
    "(with https://medium.com/codex/a-comprehensive-tutorial-to-pytorch-distributeddataparallel-1f4b42bb1b51 and pytorch tutorial as theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541e35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbd1e1e0",
   "metadata": {},
   "source": [
    "# 0. DP, DDP 공통 샘플 코드\n",
    "우리는 위의 AI summer (https://theaisummer.com/distributed-training-pytorch/)  것을 써서 할 것이다. 따라서, DP, DDP 둘다 공통으로 사용하는 코드를 쓸 것이다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f14b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#common imports\n",
    "import torch\n",
    "import torchvision\n",
    "import tor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d83d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d51851e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dbd120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a2f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0522bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96be2adc",
   "metadata": {},
   "source": [
    "== 밑에 : torch tutorial을 하려고 했는데, 위에 aisummer이 훨씬 더 잘 해서, 그것을 쓰리고함.. 따라서 **밑의 것은 대부분 무시해도 될듯**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd74806",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31e37ee4",
   "metadata": {},
   "source": [
    "# 1. use `DataParallel`\n",
    "lots of overhead so slow, but easy to implement \n",
    "\n",
    "looked at tutorial : https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fcb6af",
   "metadata": {},
   "source": [
    "## 1.0. setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96896e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#some parameters to use\n",
    "input_size = 5\n",
    "output_size = 2\n",
    "\n",
    "batch_size = 30\n",
    "data_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da62575a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7fb421",
   "metadata": {},
   "source": [
    "## 1.1. Dataset, Model등을 일반적으로 하듯이 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d5cfad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 임의로 만들기\n",
    "class dummy_dataset(Dataset):\n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, size) #임의의 데이터 (of shape length x size) 를 만들어내기 \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len #즉, 그냥 받아오도록 하기 \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "#그걸로 임의로 dataloader만들어서 intialize시키기\n",
    "dummy_loader = DataLoader(dataset = dummy_dataset(size = input_size, length=data_size),\n",
    "                        batch_size = batch_size, shuffle = True)\n",
    "\n",
    "##testing it out\n",
    "#print(dummy_loader)\n",
    "#print(next(iter(dummy_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58602e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model임의로 만들기\n",
    "class Model(nn.Module): \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(self.input_size, self.output_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.fc(input) #single layer NN\n",
    "        print('\\tIn MOdel : input size', input.size(),\n",
    "             'output_size', output.size())\n",
    "        return output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca4912",
   "metadata": {},
   "source": [
    "## ?X?X?X?X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aaf5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size, output_size)\n",
    "\n",
    "if torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b61ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf083f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ee92e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4,5'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21fee85",
   "metadata": {},
   "source": [
    "#### torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5400514",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f209d895",
   "metadata": {},
   "source": [
    "## 2. DDP\n",
    "https://medium.com/codex/a-comprehensive-tutorial-to-pytorch-distributeddataparallel-1f4b42bb1b51\n",
    "\n",
    "위에 랑\n",
    "\n",
    "https://theaisummer.com/distributed-training-pytorch/\n",
    "여기 보기!!\n",
    "(torch documentation/tutorial 보다 잘 되어있는 듯?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af51429d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

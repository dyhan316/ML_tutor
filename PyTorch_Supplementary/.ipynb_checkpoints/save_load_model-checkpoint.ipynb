{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.save (general checkpoint)\n",
    "\n",
    "* easier (not that useful) : https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html\n",
    "* full tutorial (with all about checkpoints and etc) : https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
    "\n",
    "* what I made a this tutorial out of : \n",
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-multiple-models-in-one-file\n",
    "\n",
    "\n",
    "두번째 것 보고 하자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. loading and saving models\n",
    "(prereqs : Ordered Dict 보고오기 (이미 정리해놓은 ipynb가 같은 디렉토리에 있다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. basic saving and loading\n",
    "**PyTorch : parameter 값들을, internal state dictionary called `state_dict`에 저장을 해둠!**\n",
    "\n",
    "#### `state_dict`이란?\n",
    "* model, optimizer의 state, parameter value등등을 **ordered dictionary** 형태로 저장한 것! \n",
    "\n",
    "<br>\n",
    "\n",
    "#### 따라서, 이 state_dict을 저장/불러오기 하면된다! 하는 방법은 다음과 같음\n",
    "* 저장 : `torch.save(model.state_dict())`\n",
    "* 불러오기 : `model = Model()` **후** `model.load_state_dict(torch.load(PATH))` \n",
    "    * 즉, 먼저 model instance를 **만든후** weight값들을 얹는다!\n",
    "\n",
    "\n",
    "    * `torch.save`로 이 `state_dict`를 저장 가능!\n",
    "\n",
    "(model자체를 pickle(?)로 저장할 수 있다는데, 일단은 안함!(`state_dict()`를 저장하는 것의 거의 대부분이라고 해서)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = TheModelClass()\n",
    "# Initialize optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 `state_dict`이 뭔지 보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'>\n",
      "Model's state_dict : \n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([120, 400])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([84, 120])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "\n",
      "Optimizer's state_dict : \n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n"
     ]
    }
   ],
   "source": [
    "print(type(model.state_dict())) #즉, state_dict는 ordred dict type이다. \n",
    "\n",
    "print(\"Model's state_dict : \")\n",
    "for key in model.state_dict():\n",
    "    print(key, '\\t', model.state_dict()[key].shape)\n",
    "\n",
    "#즉, model.state_dict()는 ordred dict with the individual \n",
    "#parameter tensors as the keys and its vazlues as the values\n",
    "    \n",
    "print(\"\\nOptimizer's state_dict : \")\n",
    "for key in optimizer.state_dict():\n",
    "    print(key, '\\t', optimizer.state_dict()[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 save/load only the model (not a \"general\" checkpoint) \n",
    "* `state_dict()`를 저장하도록 하자 \n",
    "* only useful for inference btw, since optimizer등등을 저장 안했으니"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##saving\n",
    "torch.save(model.state_dict(),\"./model_ckpt.pth\")\n",
    "\n",
    "##loading\n",
    "model = TheModelClass() #먼저 initialize해야함!!!\n",
    "imported_state_dict = torch.load('./model_ckpt.pth') #import(load) state dict!\n",
    "model.load_state_dict(imported_state_dict)           #load imported state dict!\n",
    "model.eval() #if want to the eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.3. General Checkpoint\n",
    "만약 training을 다시 할 목적이라면, optimizer의 state dict, 현재 epoch 등등도 저장해야한다! 이것을 어떻게 할지 보자\n",
    "\n",
    "* `torch.save(<the dictionary>)` 로 하되, `<the dictionary>`안에 model, optimizer state_dict, epoch값 등등을 넣자\n",
    "*  `ckpt = torch.load(XX)`로 dictionary를 load 한 후에, `ckpt['XX']`식으로, model_state_dict등을 하나하나 부르면 된다 \n",
    "\n",
    "<br>\n",
    "\n",
    "#### **즉, `torch.save`는 `state_dict`뿐만이 어떤 dictinoary더라도 저장할 수 있는 용도다!** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###SAVING THE GENERAL CHECKPOINT\n",
    "from collections import OrderedDict\n",
    "save_path = './checkpoint.pth'\n",
    "dict_to_save = OrderedDict({'epoch': 10, \n",
    "                            'model_state_dict':model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'loss' : 0.3 })\n",
    "#dictionary 값이 dictionary이기도 하다!\n",
    "type(dict_to_save['model_state_dict'])\n",
    "\n",
    "torch.save(dict_to_save, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'loss'])\n",
      "10 0.3\n"
     ]
    }
   ],
   "source": [
    "###LOADING THE GENERAL CHECKPOINT\n",
    "model = TheModelClass()\n",
    "optimizer = optim.SGD(params = model.parameters(), lr = 0.01)\n",
    "\n",
    "checkpoint = torch.load(save_path)    #load the checkpiont that has all the state_dict and so on\n",
    "print(checkpoint.keys()) #위에서 했떤 것처럼, \n",
    "\n",
    "\n",
    "##now let's load the model and opitmizer's state_dict and others\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "print(epoch, loss )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. DDP checkopint등도 있기는 한데, 스킵한다 \n",
    "(https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-multiple-models-in-one-file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITGAN_node2",
   "language": "python",
   "name": "itgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

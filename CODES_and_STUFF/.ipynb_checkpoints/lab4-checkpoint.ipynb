{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDxtMC2g66gQ"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4709,
     "status": "ok",
     "timestamp": 1654573242891,
     "user": {
      "displayName": "­유은이 / 학생 / 데이터사이언스학과",
      "userId": "13602239954273849034"
     },
     "user_tz": -540
    },
    "id": "vj2CXov7JJqq",
    "outputId": "f3feaad3-1cd6-409c-afbe-7acca4bdb037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcKp4bZiJwut"
   },
   "outputs": [],
   "source": [
    "%cd 'your_drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHKo6dP6eEO6"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOnSsL1EeG85"
   },
   "outputs": [],
   "source": [
    "SEED = 1111\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PgCsIyawXoN"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Lvt4lGJIe8i"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0,str(Path().absolute().joinpath(\"data\")))\n",
    "from data import prepareData\n",
    "import random\n",
    "random.seed(SEED)\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "TRAIN_RATIO = 0.6\n",
    "VALID_RATIO = 0.2\n",
    "\n",
    "# BATCH_SIZE = 64\n",
    "BATCH_SIZE = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fePBsU2GKoaI"
   },
   "outputs": [],
   "source": [
    "class TranslateDataset(Dataset):\n",
    "    def __init__(self, max_length=10, fra2eng=True):\n",
    "        self.input_lang, self.output_lang, self.pairs = prepareData('eng', 'fra', max_length=max_length, reverse=fra2eng)\n",
    "        self.max_length=max_length\n",
    "\n",
    "        self.input_lang.addWord('PAD')\n",
    "        self.output_lang.addWord('PAD')\n",
    "        self.input_lang_pad = self.input_lang.word2index['PAD']\n",
    "        self.output_lang_pad = self.output_lang.word2index['PAD']\n",
    "        \n",
    "        print(\"data example\")\n",
    "        print(random.choice(self.pairs))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        x, y = self._tensorsFromPair(pair)\n",
    "        return x, y\n",
    "\n",
    "    def _tensorFromSentence(self, lang, sentence):\n",
    "        indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
    "        indexes.append(EOS_token)\n",
    "        return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "    def _tensorsFromPair(self, pair):\n",
    "        input_tensor = self._tensorFromSentence(self.input_lang, pair[0])\n",
    "        target_tensor = self._tensorFromSentence(self.output_lang, pair[1])\n",
    "        return (input_tensor, target_tensor)\n",
    "    \n",
    "    def collate_fn(self, data):\n",
    "        x_batch = []; y_batch = []\n",
    "        \n",
    "        for x, y in data:\n",
    "            if x.shape[0] < self.max_length-1:\n",
    "                x = torch.cat([x, self.input_lang_pad*torch.ones((self.max_length-1 - x.shape[0], 1), dtype=x.dtype)])\n",
    "            elif x.shape[0] > self.max_length-1:\n",
    "                x = x[:self.max_length-1]\n",
    "            if y.shape[0] < self.max_length-1:\n",
    "                y = torch.cat([y, self.output_lang_pad*torch.ones((self.max_length-1 - y.shape[0], 1), dtype=y.dtype)])\n",
    "            elif y.shape[0] > self.max_length-1:\n",
    "                y = y[:self.max_length-1]\n",
    "\n",
    "            x_batch.append(torch.cat([torch.tensor([SOS_token]), x.squeeze(1)]))\n",
    "            y_batch.append(torch.cat([torch.tensor([SOS_token]), y.squeeze(1)]))\n",
    "        \n",
    "        return torch.stack(x_batch), torch.stack(y_batch)\n",
    "\n",
    "dataset = TranslateDataset(max_length=MAX_LENGTH)\n",
    "\n",
    "train_size = int(len(dataset)*TRAIN_RATIO)\n",
    "valid_size = int(len(dataset)*VALID_RATIO)\n",
    "train_data, valid_data, test_data = random_split(dataset, [train_size, valid_size, len(dataset)-(train_size+valid_size)],)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6lIHD3Xf6Ik"
   },
   "outputs": [],
   "source": [
    "sample_x, sample_y = next(iter(train_dataloader))\n",
    "sample_x = sample_x.squeeze(0)\n",
    "sample_y = sample_y.squeeze(0)\n",
    "\n",
    "print(\"Sample sentences\\n\")\n",
    "print(\"sample_x: \", sample_x)\n",
    "print(' '.join([dataset.input_lang.index2word[i] for i in sample_x.tolist()]))\n",
    "print(\"sample_y: \", sample_y)\n",
    "print(' '.join([dataset.output_lang.index2word[i] for i in sample_y.tolist()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TqutY58tG-h"
   },
   "source": [
    "# 1. Seq2seq model with Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgIpHf60hRfY"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "##### Initialize Model ######\n",
    "#############################\n",
    "\n",
    "in_dim =  # french\n",
    "out_dim =  # english\n",
    "\n",
    "emb_dim =  # embbeding size\n",
    "hid_dim =  # vector size of encoder output\n",
    "\n",
    "print(f'\\nin_dim: {in_dim}\\tout_dim: {out_dim}\\temb_dim: {emb_dim}\\thid_dim: {hid_dim}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFDRFkQTC3YQ"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbSJB9B-jl-4"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "####### Prepare Input ####### \n",
    "#############################\n",
    "\n",
    "print('Encoder Embedding outputs')\n",
    "\n",
    "embedded_x = nn.Embedding(in_dim, emb_dim)(sample_x)\n",
    "print(embedded_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEH1RRbe1DrA"
   },
   "outputs": [],
   "source": [
    "print('Initialize hidden and cell states')\n",
    "\n",
    "hidden_0 =  # (1, Hout) for unbatched input\n",
    "cell_0 =  # (1, Hcell) for unbatched input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XveBtVbhkMWp"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "### Get output of Encoder ###\n",
    "#############################\n",
    " \n",
    "lstm = nn.LSTM(input_size=emb_dim, hidden_size=hid_dim)\n",
    "hiddens, (hidden, cell) = lstm(embedded_x, (hidden_0, cell_0))\n",
    "# hiddens = lstm(embedded_x, (hidden_0, cell_0))\n",
    "\n",
    "print('LSTM Encoder outputs')\n",
    "print(f'hiddens: {hiddens.shape}\\thidden: {hidden.shape}\\tcell: {cell.shape}')\n",
    "\n",
    "enc_hiddens = hiddens # assign encoder outputs for decoder(w/attention, see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZhSxF7Kk89l"
   },
   "outputs": [],
   "source": [
    "# torch.sum(hiddens[-1]-hidden) # last value of hiddens = hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3jkpgL7C7-_"
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdho8e70mV6h"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "###### Prepare Output ####### \n",
    "#############################\n",
    "\n",
    "print('Decoder Embedding outputs')\n",
    "\n",
    "dec_embedder = nn.Embedding(out_dim, emb_dim)\n",
    "embedded_y = dec_embedder(sample_y) # ground truth\n",
    "print(embedded_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHABukOMpY6u"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "####### Prepare Input ####### \n",
    "#############################\n",
    "\n",
    "cell_0 = torch.zeros(1, hid_dim)\n",
    "\n",
    "input = embedded_y[0] # [SOS]\n",
    "enc_output = hiddens[-1] # hidden\n",
    "hidden = enc_output.unsqueeze(0)\n",
    "cell = cell_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l81Du2A-20uI"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "### Get output of Decoder ###\n",
    "#############################\n",
    "\n",
    "seq2seq_outputs = []\n",
    "decoder = nn.LSTM(input_size=emb_dim+hid_dim, hidden_size=hid_dim)\n",
    "fc = nn.Linear(hid_dim, out_dim)\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "\n",
    "    input_encout_concat = torch.concat([input, enc_output])\n",
    "    \n",
    "    hiddens, (hidden, cell) = decoder(input_encout_concat.unsqueeze(0), (hidden, cell))\n",
    "    \n",
    "    next_token_idx = F.softmax(fc(hidden)).max(1)[1]\n",
    "    \n",
    "    seq2seq_outputs.append(hiddens)\n",
    "    \n",
    "\n",
    "    # Update inputs for the next loop\n",
    "    \n",
    "    input = dec_embedder(next_token_idx).squeeze(0)\n",
    "    # hidden = hidden\n",
    "    # cell = cell\n",
    "\n",
    "\n",
    "\n",
    "    if t==0: \n",
    "        print(f'input_encout_concat: {input_encout_concat.shape}')\n",
    "        print('\\nLSTM Decoder outputs')\n",
    "        print(f'hiddens: {hiddens.shape}\\thidden: {hidden.shape}\\tcell: {cell.shape}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shLkhz5mv8TT"
   },
   "outputs": [],
   "source": [
    "seq2seq_outputs = torch.stack(seq2seq_outputs)\n",
    "seq2seq_outputs.shape # predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tvzu6ONF2TyE"
   },
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1654570133314,
     "user": {
      "displayName": "­유은이 / 학생 / 데이터사이언스학과",
      "userId": "13602239954273849034"
     },
     "user_tz": -540
    },
    "id": "DrmqlFUAw4b7",
    "outputId": "b212a92f-6e70-4a12-c738-58192aebf3b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key/value shape:\t torch.Size([10, 512])\n",
      "Query shape:\t torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "## Set key/value and query ##\n",
    "#############################\n",
    "\n",
    "# key, value\n",
    "kv = enc_hiddens\n",
    "print(\"Key/value shape:\\t\",  kv.shape)\n",
    "\n",
    "# query\n",
    "example_t = 4 # any int [0 ~ MAX_LENGTH-1]\n",
    "q = seq2seq_outputs[example_t]\n",
    "print(\"Query shape:\\t\",  q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1654570293580,
     "user": {
      "displayName": "­유은이 / 학생 / 데이터사이언스학과",
      "userId": "13602239954273849034"
     },
     "user_tz": -540
    },
    "id": "lSsUqg_8x4y-",
    "outputId": "14f07d04-7151-4549-e3a0-172dae9255b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_score shape:\t torch.Size([10, 1])\n",
      "weights: \t [0.06483325362205505, 0.09662076085805893, 0.10265860706567764, 0.09185811132192612, 0.06566578149795532, 0.089730404317379, 0.1004531979560852, 0.1402510553598404, 0.10215922445058823, 0.14576959609985352]\n",
      "total of weights: \t 0.9999999925494194\n",
      "weighted sum of val:\t torch.Size([10, 512])\n",
      "weighted sum:\t torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "#### Get attention value ####\n",
    "#############################\n",
    "\n",
    "attn_score =  #(10, 1)\n",
    "\n",
    "attn_coefficient =  #(10, 1)\n",
    "\n",
    "weighted_kv = kv*attn_coefficient\n",
    "weighted_sum = torch.sum(weighted_kv, dim=0) # attention value\n",
    "\n",
    "print(\"attn_score shape:\\t\",  attn_score.shape)\n",
    "print(\"weights: \\t\", attn_coefficient.squeeze(1).tolist())\n",
    "print(\"total of weights: \\t\", sum(attn_coefficient.squeeze(1).tolist()))\n",
    "print(\"weighted sum of val:\\t\", weighted_kv.shape)\n",
    "print(\"weighted sum:\\t\", weighted_sum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1654573944008,
     "user": {
      "displayName": "­유은이 / 학생 / 데이터사이언스학과",
      "userId": "13602239954273849034"
     },
     "user_tz": -540
    },
    "id": "Mh495Oi1zwyP",
    "outputId": "8a786094-8138-45ce-e41d-5fae4437d507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before attn\n",
      "tensor(-0.9780, grad_fn=<AddBackward0>)\n",
      "attn weight\n",
      "tensor([0.0657], grad_fn=<SelectBackward0>)\n",
      "after attn\n",
      "tensor(-0.0642, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 4  # which index of encoder output to attend [0~9]\n",
    "\n",
    "print(\"before attn\")\n",
    "print(sum(kv[sample_idx]))\n",
    "print(\"attn weight\")\n",
    "print(attn_coefficient[sample_idx])\n",
    "print(\"after attn\")\n",
    "print(sum(weighted_kv[sample_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siPUPEFXEbrD"
   },
   "source": [
    "# 2. Seq2seq model with Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5yc8iJ9GFrJ"
   },
   "outputs": [],
   "source": [
    "in_dim = dataset.input_lang.n_words\n",
    "out_dim = dataset.output_lang.n_words\n",
    "emb_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZw7whv9GSdY"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "########### Input ########### \n",
    "#############################\n",
    "\n",
    "embedded_x = nn.Embedding(in_dim, emb_dim)(sample_x)\n",
    "print(\"embedded_x:\\t\", embedded_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sz_9Y4Q9Ecrt"
   },
   "source": [
    "Positional Encoding\n",
    "1. Absolute sinusoid-based Positional Encoding\n",
    "2. Relative Positional Encoding\n",
    "3. Learnable Embedding (using nn.Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIg5RLUzEXQc"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "##### Position Encoding #####\n",
    "#############################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Learnable\n",
    "# pos = torch.arange(MAX_LENGTH).unsqueeze(1)\n",
    "# pos_embedding = nn.Embedding(in_dim, emb_dim)(pos)\n",
    "# plt.pcolormesh(pos_embedding.squeeze(1).detach().numpy(), cmap='RdBu') # Learnable\n",
    "\n",
    "# Absolute\n",
    "with open('absolute_pe.pickle', 'rb') as handle:\n",
    "    pe = pickle.load(handle)\n",
    "plt.pcolormesh(pe.squeeze(1), cmap='RdBu')\n",
    "\n",
    "\n",
    "plt.xlim((0, emb_dim))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aiLvHDrm9MC4"
   },
   "outputs": [],
   "source": [
    "embedded_pos = embedded_x + pe.squeeze(1)\n",
    "print(\"embedded_pos:\\t\",embedded_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBizStE9POJR"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "##### src * trg masking #####\n",
    "#############################\n",
    "\n",
    "# source masking\n",
    "sample_x_mask = (sample_x == dataset.input_lang_pad)\n",
    "\n",
    "print(\"source mask = pad masking\")\n",
    "print(sample_x_mask.squeeze().tolist())\n",
    "\n",
    "# target masking\n",
    "pad_mask_neg = (sample_y != dataset.output_lang_pad).unsqueeze(1).unsqueeze(2)\n",
    "sub_mask = torch.tril(torch.ones((MAX_LENGTH, MAX_LENGTH))).bool()\n",
    "sample_y_mask = pad_mask_neg.permute(2,1,0) & sub_mask.unsqueeze(0)\n",
    "\n",
    "print(\"\\ntarget mask = pad masking + subsequent masking\")\n",
    "print(pad_mask_neg.squeeze().tolist())\n",
    "print()\n",
    "print(sub_mask.squeeze())\n",
    "print()\n",
    "print(sample_y_mask.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-NgAbGqIFco"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "########### Model ########### \n",
    "#############################\n",
    "\n",
    "from torch.nn import Transformer\n",
    "\n",
    "hid_dim = emb_dim\n",
    "ff_dim = 1024\n",
    "n_heads = 8\n",
    "n_enc_layers = 3\n",
    "n_dec_layers = 5\n",
    "dropout_p = 0.1\n",
    "\n",
    "class TransSeq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, hid_dim, ff_dim, n_heads, n_enc_layers, n_dec_layers, dropout_p):\n",
    "        super().__init__()\n",
    "        self.input_emb = nn.Embedding(in_dim, hid_dim)\n",
    "        self.output_emb = nn.Embedding(out_dim, hid_dim)\n",
    "        self.pos_emb = nn.Embedding(MAX_LENGTH, hid_dim)\n",
    "\n",
    "        self.transformer = Transformer(d_model=hid_dim,\n",
    "                                       nhead=n_heads,\n",
    "                                       num_encoder_layers=n_enc_layers,\n",
    "                                       num_decoder_layers=n_dec_layers,\n",
    "                                       dim_feedforward = ff_dim,\n",
    "                                       dropout = dropout_p,\n",
    "                                       activation = 'gelu')\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        embedded_pos = self.pos_emb(torch.arange(MAX_LENGTH).unsqueeze(1))\n",
    "        embedded_x = self.input_emb(src)\n",
    "        embedded_y = self.output_emb(trg)\n",
    "\n",
    "        embedded_x = self.dropout(torch.sum(embedded_x + embedded_pos, dim=1))\n",
    "        embedded_y = self.dropout(torch.sum(embedded_y + embedded_pos, dim=1))\n",
    "\n",
    "        return self.transformer(embedded_x, embedded_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EljQjKn0JYkc"
   },
   "outputs": [],
   "source": [
    "model = TransSeq2Seq(hid_dim, ff_dim, n_heads, n_enc_layers, n_dec_layers, dropout_p)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3no_Y49MPA7_"
   },
   "outputs": [],
   "source": [
    "out = model(sample_x, sample_y)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDma7XS2eKSQ"
   },
   "source": [
    "# 3. Bert fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaKMY_DfUDmC"
   },
   "source": [
    "ref.\n",
    "\n",
    "1. [huggingface BERT documentation](https://huggingface.co/transformers/v3.0.2/model_doc/bert.html#bert)\n",
    "\n",
    "2. [masked language modelling with bert](https://towardsdatascience.com/masked-language-modelling-with-bert-7d49793e5d2c)\n",
    "\n",
    "3. [fine-tuning bert for text classification in pytorch](https://luv-bansal.medium.com/fine-tuning-bert-for-text-classification-in-pytorch-503d97342db2)\n",
    "\n",
    "4. [pytorch sentiment classification github](https://github.com/clairett/pytorch-sentiment-classification/tree/master/data/SST2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUQDOmLDeMPo"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "\n",
    "MX_LENGTH = 50\n",
    "BATCH_SIZE = 32\n",
    "MASK_RATIO = 0.2\n",
    "EPOCHS = 3\n",
    "learning_rate = 5e-3 #5e-5 -> loss: 1~2 after one epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYOw7wn8_YIi"
   },
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Fp3gP2nfTga"
   },
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, tokenizer, max_length=512, mask_ratio=0.15):\n",
    "        super(BertDataset, self).__init__()\n",
    "        # self.root_dir='./data'\n",
    "        self.train_csv=pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
    "        self.tokenizer=tokenizer\n",
    "        self.target=self.train_csv.iloc[:,1]\n",
    "        self.max_length = max_length\n",
    "        self.mask_ratio = mask_ratio\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_csv)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(text=self.train_csv.iloc[index,0],\n",
    "                                            padding='max_length',\n",
    "                                            truncation=True,\n",
    "                                            add_special_tokens=True,\n",
    "                                            return_tensors='pt',\n",
    "                                            max_length=self.max_length,)\n",
    "\n",
    "        return {'input_ids': inputs[\"input_ids\"].clone().detach(),\n",
    "                'token_type_ids': inputs[\"token_type_ids\"].clone().detach(),}\n",
    "\n",
    "    def _apply_masking(self, x):\n",
    "        rand = torch.rand(x['input_ids'].shape)\n",
    "        mask = (rand < self.mask_ratio) * (x['input_ids'] != 101) * (x['input_ids'] != 102) * (x['input_ids'] != 0) # t/f tensor\n",
    "\n",
    "        selection = torch.flatten(mask[0].nonzero()).tolist() # idxs masked\n",
    "        x['input_ids'][0, selection] = 103 # apply MASK token\n",
    "\n",
    "        return x\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        batch={'input_ids':None, 'labels':None}\n",
    "        \n",
    "        # copy ids\n",
    "        tmp = [item['input_ids'] for item in data]\n",
    "        batch['labels'] = torch.stack(tmp).squeeze(1)\n",
    "        \n",
    "        # create mask tensor\n",
    "        data = list(map(self._apply_masking, data))\n",
    "        tmp = [item['input_ids'] for item in data]\n",
    "        batch['input_ids'] = torch.stack(tmp).squeeze(1)\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXoIN3AgAlnb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# dataset\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset= BertDataset(tokenizer, max_length=MX_LENGTH, mask_ratio=MASK_RATIO)\n",
    "\n",
    "# dataloader\n",
    "dataloader=DataLoader(dataset=dataset,batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "128XnwZsiZoD"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "###### Explore Dataset ######\n",
    "#############################\n",
    "\n",
    "for i, batch_data in enumerate(dataloader):\n",
    "    if i==0:\n",
    "        print(\"data shape\")\n",
    "        print(batch_data['labels'].shape) # batch_size * max_length\n",
    "        print()\n",
    "        print(\"before masking\")\n",
    "        print(batch_data['labels'][0]) # 101: CLS, 102: SEP / we use single sentence for fine-tuning task\n",
    "        print()\n",
    "        print(\"after masking (MASK = 103)\")\n",
    "        print(batch_data['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbAF5GNP_a3h"
   },
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9xtPgQlh_y4"
   },
   "outputs": [],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbmqvJeriX95"
   },
   "outputs": [],
   "source": [
    "for i, batch_data in enumerate(dataloader):\n",
    "    if i==0:\n",
    "        print(model(**batch_data).loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5TYnU7D_p_J"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OC9pa0_QxYvA"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 243368,
     "status": "ok",
     "timestamp": 1654580649024,
     "user": {
      "displayName": "­유은이 / 학생 / 데이터사이언스학과",
      "userId": "13602239954273849034"
     },
     "user_tz": -540
    },
    "id": "o8yVp0yjy1j0",
    "outputId": "50d02762-f78a-4a2a-d6d9-6f511cd4a174"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 217/217 [01:21<00:00,  2.66it/s, loss=4.86]\n",
      "Epoch 1: 100%|██████████| 217/217 [01:20<00:00,  2.68it/s, loss=4.74]\n",
      "Epoch 2: 100%|██████████| 217/217 [01:20<00:00,  2.68it/s, loss=4.72]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxusA873CoGz"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data = np.array(((1,1),(2,3),(3,4),(-0.5,-0.5), (-1,-2),(-2,-3),( -3,-4),(-4,-3)))\n",
    "label = np.array((1,1,1,-1,-1,-1,-1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9cb02c9520>,\n",
       " <matplotlib.lines.Line2D at 0x7f9cb02c97c0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPoGK5zfBeU8t4DtSM/Vsr/",
   "collapsed_sections": [
    "EDxtMC2g66gQ",
    "5PgCsIyawXoN",
    "8TqutY58tG-h",
    "aFDRFkQTC3YQ",
    "m3jkpgL7C7-_",
    "Tvzu6ONF2TyE",
    "siPUPEFXEbrD",
    "ZDma7XS2eKSQ",
    "SYOw7wn8_YIi",
    "xbAF5GNP_a3h",
    "g5TYnU7D_p_J"
   ],
   "name": "lab4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDxtMC2g66gQ"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4709,
     "status": "ok",
     "timestamp": 1654573242891,
     "user": {
      "displayName": "­유은이 / 학생 / 데이터사이언스학과",
      "userId": "13602239954273849034"
     },
     "user_tz": -540
    },
    "id": "vj2CXov7JJqq",
    "outputId": "f3feaad3-1cd6-409c-afbe-7acca4bdb037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcKp4bZiJwut"
   },
   "outputs": [],
   "source": [
    "%cd 'your_drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHKo6dP6eEO6"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOnSsL1EeG85"
   },
   "outputs": [],
   "source": [
    "SEED = 1111\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PgCsIyawXoN"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Lvt4lGJIe8i"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0,str(Path().absolute().joinpath(\"data\")))\n",
    "from data import prepareData\n",
    "import random\n",
    "random.seed(SEED)\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "TRAIN_RATIO = 0.6\n",
    "VALID_RATIO = 0.2\n",
    "\n",
    "# BATCH_SIZE = 64\n",
    "BATCH_SIZE = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fePBsU2GKoaI"
   },
   "outputs": [],
   "source": [
    "class TranslateDataset(Dataset):\n",
    "    def __init__(self, max_length=10, fra2eng=True):\n",
    "        self.input_lang, self.output_lang, self.pairs = prepareData('eng', 'fra', max_length=max_length, reverse=fra2eng)\n",
    "        self.max_length=max_length\n",
    "\n",
    "        self.input_lang.addWord('PAD')\n",
    "        self.output_lang.addWord('PAD')\n",
    "        self.input_lang_pad = self.input_lang.word2index['PAD']\n",
    "        self.output_lang_pad = self.output_lang.word2index['PAD']\n",
    "        \n",
    "        print(\"data example\")\n",
    "        print(random.choice(self.pairs))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        x, y = self._tensorsFromPair(pair)\n",
    "        return x, y\n",
    "\n",
    "    def _tensorFromSentence(self, lang, sentence):\n",
    "        indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
    "        indexes.append(EOS_token)\n",
    "        return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "    def _tensorsFromPair(self, pair):\n",
    "        input_tensor = self._tensorFromSentence(self.input_lang, pair[0])\n",
    "        target_tensor = self._tensorFromSentence(self.output_lang, pair[1])\n",
    "        return (input_tensor, target_tensor)\n",
    "    \n",
    "    def collate_fn(self, data):\n",
    "        x_batch = []; y_batch = []\n",
    "        \n",
    "        for x, y in data:\n",
    "            if x.shape[0] < self.max_length-1:\n",
    "                x = torch.cat([x, self.input_lang_pad*torch.ones((self.max_length-1 - x.shape[0], 1), dtype=x.dtype)])\n",
    "            elif x.shape[0] > self.max_length-1:\n",
    "                x = x[:self.max_length-1]\n",
    "            if y.shape[0] < self.max_length-1:\n",
    "                y = torch.cat([y, self.output_lang_pad*torch.ones((self.max_length-1 - y.shape[0], 1), dtype=y.dtype)])\n",
    "            elif y.shape[0] > self.max_length-1:\n",
    "                y = y[:self.max_length-1]\n",
    "\n",
    "            x_batch.append(torch.cat([torch.tensor([SOS_token]), x.squeeze(1)]))\n",
    "            y_batch.append(torch.cat([torch.tensor([SOS_token]), y.squeeze(1)]))\n",
    "        \n",
    "        return torch.stack(x_batch), torch.stack(y_batch)\n",
    "\n",
    "dataset = TranslateDataset(max_length=MAX_LENGTH)\n",
    "\n",
    "train_size = int(len(dataset)*TRAIN_RATIO)\n",
    "valid_size = int(len(dataset)*VALID_RATIO)\n",
    "train_data, valid_data, test_data = random_split(dataset, [train_size, valid_size, len(dataset)-(train_size+valid_size)],)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6lIHD3Xf6Ik"
   },
   "outputs": [],
   "source": [
    "sample_x, sample_y = next(iter(train_dataloader))\n",
    "sample_x = sample_x.squeeze(0)\n",
    "sample_y = sample_y.squeeze(0)\n",
    "\n",
    "print(\"Sample sentences\\n\")\n",
    "print(\"sample_x: \", sample_x)\n",
    "print(' '.join([dataset.input_lang.index2word[i] for i in sample_x.tolist()]))\n",
    "print(\"sample_y: \", sample_y)\n",
    "print(' '.join([dataset.output_lang.index2word[i] for i in sample_y.tolist()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TqutY58tG-h"
   },
   "source": [
    "# 1. Seq2seq model with Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgIpHf60hRfY"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "##### Initialize Model ######\n",
    "#############################\n",
    "\n",
    "in_dim =  # french\n",
    "out_dim =  # english\n",
    "\n",
    "emb_dim =  # embbeding size\n",
    "hid_dim =  # vector size of encoder output\n",
    "\n",
    "print(f'\\nin_dim: {in_dim}\\tout_dim: {out_dim}\\temb_dim: {emb_dim}\\thid_dim: {hid_dim}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFDRFkQTC3YQ"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbSJB9B-jl-4"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "####### Prepare Input ####### \n",
    "#############################\n",
    "\n",
    "print('Encoder Embedding outputs')\n",
    "\n",
    "embedded_x = nn.Embedding(in_dim, emb_dim)(sample_x)\n",
    "print(embedded_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEH1RRbe1DrA"
   },
   "outputs": [],
   "source": [
    "print('Initialize hidden and cell states')\n",
    "\n",
    "hidden_0 =  # (1, Hout) for unbatched input\n",
    "cell_0 =  # (1, Hcell) for unbatched input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XveBtVbhkMWp"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "### Get output of Encoder ###\n",
    "#############################\n",
    " \n",
    "lstm = nn.LSTM(input_size=emb_dim, hidden_size=hid_dim)\n",
    "hiddens, (hidden, cell) = lstm(embedded_x, (hidden_0, cell_0))\n",
    "# hiddens = lstm(embedded_x, (hidden_0, cell_0))\n",
    "\n",
    "print('LSTM Encoder outputs')\n",
    "print(f'hiddens: {hiddens.shape}\\thidden: {hidden.shape}\\tcell: {cell.shape}')\n",
    "\n",
    "enc_hiddens = hiddens # assign encoder outputs for decoder(w/attention, see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZhSxF7Kk89l"
   },
   "outputs": [],
   "source": [
    "# torch.sum(hiddens[-1]-hidden) # last value of hiddens = hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3jkpgL7C7-_"
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdho8e70mV6h"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "###### Prepare Output ####### \n",
    "#############################\n",
    "\n",
    "print('Decoder Embedding outputs')\n",
    "\n",
    "dec_embedder = nn.Embedding(out_dim, emb_dim)\n",
    "embedded_y = dec_embedder(sample_y) # ground truth\n",
    "print(embedded_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHABukOMpY6u"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "####### Prepare Input ####### \n",
    "#############################\n",
    "\n",
    "cell_0 = torch.zeros(1, hid_dim)\n",
    "\n",
    "input = embedded_y[0] # [SOS]\n",
    "enc_output = hiddens[-1] # hidden\n",
    "hidden = enc_output.unsqueeze(0)\n",
    "cell = cell_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l81Du2A-20uI"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "### Get output of Decoder ###\n",
    "#############################\n",
    "\n",
    "seq2seq_outputs = []\n",
    "decoder = nn.LSTM(input_size=emb_dim+hid_dim, hidden_size=hid_dim)\n",
    "fc = nn.Linear(hid_dim, out_dim)\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "\n",
    "    input_encout_concat = torch.concat([input, enc_output])\n",
    "    \n",
    "    hiddens, (hidden, cell) = decoder(input_encout_concat.unsqueeze(0), (hidden, cell))\n",
    "    \n",
    "    next_token_idx = F.softmax(fc(hidden)).max(1)[1]\n",
    "    \n",
    "    seq2seq_outputs.append(hiddens)\n",
    "    \n",
    "\n",
    "    # Update inputs for the next loop\n",
    "    \n",
    "    input = dec_embedder(next_token_idx).squeeze(0)\n",
    "    # hidden = hidden\n",
    "    # cell = cell\n",
    "\n",
    "\n",
    "\n",
    "    if t==0: \n",
    "        print(f'input_encout_concat: {input_encout_concat.shape}')\n",
    "        print('\\nLSTM Decoder outputs')\n",
    "        print(f'hiddens: {hiddens.shape}\\thidden: {hidden.shape}\\tcell: {cell.shape}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shLkhz5mv8TT"
   },
   "outputs": [],
   "source": [
    "seq2seq_outputs = torch.stack(seq2seq_outputs)\n",
    "seq2seq_outputs.shape # predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tvzu6ONF2TyE"
   },
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1654570133314,
     "user": {
      "displayName": "­유은이 / 학생 / 데이터사이언스학과",
      "userId": "13602239954273849034"
     },
     "user_tz": -540
    },
    "id": "DrmqlFUAw4b7",
    "outputId": "b212a92f-6e70-4a12-c738-58192aebf3b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key/value shape:\t torch.Size([10, 512])\n",
      "Query shape:\t torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "## Set key/value and query ##\n",
    "#############################\n",
    "\n",
    "# key, value\n",
    "kv = enc_hiddens\n",
    "print(\"Key/value shape:\\t\",  kv.shape)\n",
    "\n",
    "# query\n",
    "example_t = 4 # any int [0 ~ MAX_LENGTH-1]\n",
    "q = seq2seq_outputs[example_t]\n",
    "print(\"Query shape:\\t\",  q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1654570293580,
     "user": {
      "displayName": "­유은이 / 학생 / 데이터사이언스학과",
      "userId": "13602239954273849034"
     },
     "user_tz": -540
    },
    "id": "lSsUqg_8x4y-",
    "outputId": "14f07d04-7151-4549-e3a0-172dae9255b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_score shape:\t torch.Size([10, 1])\n",
      "weights: \t [0.06483325362205505, 0.09662076085805893, 0.10265860706567764, 0.09185811132192612, 0.06566578149795532, 0.089730404317379, 0.1004531979560852, 0.1402510553598404, 0.10215922445058823, 0.14576959609985352]\n",
      "total of weights: \t 0.9999999925494194\n",
      "weighted sum of val:\t torch.Size([10, 512])\n",
      "weighted sum:\t torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "#### Get attention value ####\n",
    "#############################\n",
    "\n",
    "attn_score =  #(10, 1)\n",
    "\n",
    "attn_coefficient =  #(10, 1)\n",
    "\n",
    "weighted_kv = kv*attn_coefficient\n",
    "weighted_sum = torch.sum(weighted_kv, dim=0) # attention value\n",
    "\n",
    "print(\"attn_score shape:\\t\",  attn_score.shape)\n",
    "print(\"weights: \\t\", attn_coefficient.squeeze(1).tolist())\n",
    "print(\"total of weights: \\t\", sum(attn_coefficient.squeeze(1).tolist()))\n",
    "print(\"weighted sum of val:\\t\", weighted_kv.shape)\n",
    "print(\"weighted sum:\\t\", weighted_sum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1654573944008,
     "user": {
      "displayName": "­유은이 / 학생 / 데이터사이언스학과",
      "userId": "13602239954273849034"
     },
     "user_tz": -540
    },
    "id": "Mh495Oi1zwyP",
    "outputId": "8a786094-8138-45ce-e41d-5fae4437d507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before attn\n",
      "tensor(-0.9780, grad_fn=<AddBackward0>)\n",
      "attn weight\n",
      "tensor([0.0657], grad_fn=<SelectBackward0>)\n",
      "after attn\n",
      "tensor(-0.0642, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 4  # which index of encoder output to attend [0~9]\n",
    "\n",
    "print(\"before attn\")\n",
    "print(sum(kv[sample_idx]))\n",
    "print(\"attn weight\")\n",
    "print(attn_coefficient[sample_idx])\n",
    "print(\"after attn\")\n",
    "print(sum(weighted_kv[sample_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siPUPEFXEbrD"
   },
   "source": [
    "# 2. Seq2seq model with Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5yc8iJ9GFrJ"
   },
   "outputs": [],
   "source": [
    "in_dim = dataset.input_lang.n_words\n",
    "out_dim = dataset.output_lang.n_words\n",
    "emb_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZw7whv9GSdY"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "########### Input ########### \n",
    "#############################\n",
    "\n",
    "embedded_x = nn.Embedding(in_dim, emb_dim)(sample_x)\n",
    "print(\"embedded_x:\\t\", embedded_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sz_9Y4Q9Ecrt"
   },
   "source": [
    "Positional Encoding\n",
    "1. Absolute sinusoid-based Positional Encoding\n",
    "2. Relative Positional Encoding\n",
    "3. Learnable Embedding (using nn.Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIg5RLUzEXQc"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "##### Position Encoding #####\n",
    "#############################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Learnable\n",
    "# pos = torch.arange(MAX_LENGTH).unsqueeze(1)\n",
    "# pos_embedding = nn.Embedding(in_dim, emb_dim)(pos)\n",
    "# plt.pcolormesh(pos_embedding.squeeze(1).detach().numpy(), cmap='RdBu') # Learnable\n",
    "\n",
    "# Absolute\n",
    "with open('absolute_pe.pickle', 'rb') as handle:\n",
    "    pe = pickle.load(handle)\n",
    "plt.pcolormesh(pe.squeeze(1), cmap='RdBu')\n",
    "\n",
    "\n",
    "plt.xlim((0, emb_dim))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aiLvHDrm9MC4"
   },
   "outputs": [],
   "source": [
    "embedded_pos = embedded_x + pe.squeeze(1)\n",
    "print(\"embedded_pos:\\t\",embedded_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBizStE9POJR"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "##### src * trg masking #####\n",
    "#############################\n",
    "\n",
    "# source masking\n",
    "sample_x_mask = (sample_x == dataset.input_lang_pad)\n",
    "\n",
    "print(\"source mask = pad masking\")\n",
    "print(sample_x_mask.squeeze().tolist())\n",
    "\n",
    "# target masking\n",
    "pad_mask_neg = (sample_y != dataset.output_lang_pad).unsqueeze(1).unsqueeze(2)\n",
    "sub_mask = torch.tril(torch.ones((MAX_LENGTH, MAX_LENGTH))).bool()\n",
    "sample_y_mask = pad_mask_neg.permute(2,1,0) & sub_mask.unsqueeze(0)\n",
    "\n",
    "print(\"\\ntarget mask = pad masking + subsequent masking\")\n",
    "print(pad_mask_neg.squeeze().tolist())\n",
    "print()\n",
    "print(sub_mask.squeeze())\n",
    "print()\n",
    "print(sample_y_mask.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-NgAbGqIFco"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "########### Model ########### \n",
    "#############################\n",
    "\n",
    "from torch.nn import Transformer\n",
    "\n",
    "hid_dim = emb_dim\n",
    "ff_dim = 1024\n",
    "n_heads = 8\n",
    "n_enc_layers = 3\n",
    "n_dec_layers = 5\n",
    "dropout_p = 0.1\n",
    "\n",
    "class TransSeq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, hid_dim, ff_dim, n_heads, n_enc_layers, n_dec_layers, dropout_p):\n",
    "        super().__init__()\n",
    "        self.input_emb = nn.Embedding(in_dim, hid_dim)\n",
    "        self.output_emb = nn.Embedding(out_dim, hid_dim)\n",
    "        self.pos_emb = nn.Embedding(MAX_LENGTH, hid_dim)\n",
    "\n",
    "        self.transformer = Transformer(d_model=hid_dim,\n",
    "                                       nhead=n_heads,\n",
    "                                       num_encoder_layers=n_enc_layers,\n",
    "                                       num_decoder_layers=n_dec_layers,\n",
    "                                       dim_feedforward = ff_dim,\n",
    "                                       dropout = dropout_p,\n",
    "                                       activation = 'gelu')\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        embedded_pos = self.pos_emb(torch.arange(MAX_LENGTH).unsqueeze(1))\n",
    "        embedded_x = self.input_emb(src)\n",
    "        embedded_y = self.output_emb(trg)\n",
    "\n",
    "        embedded_x = self.dropout(torch.sum(embedded_x + embedded_pos, dim=1))\n",
    "        embedded_y = self.dropout(torch.sum(embedded_y + embedded_pos, dim=1))\n",
    "\n",
    "        return self.transformer(embedded_x, embedded_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EljQjKn0JYkc"
   },
   "outputs": [],
   "source": [
    "model = TransSeq2Seq(hid_dim, ff_dim, n_heads, n_enc_layers, n_dec_layers, dropout_p)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3no_Y49MPA7_"
   },
   "outputs": [],
   "source": [
    "out = model(sample_x, sample_y)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDma7XS2eKSQ"
   },
   "source": [
    "# 3. Bert fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaKMY_DfUDmC"
   },
   "source": [
    "ref.\n",
    "\n",
    "1. [huggingface BERT documentation](https://huggingface.co/transformers/v3.0.2/model_doc/bert.html#bert)\n",
    "\n",
    "2. [masked language modelling with bert](https://towardsdatascience.com/masked-language-modelling-with-bert-7d49793e5d2c)\n",
    "\n",
    "3. [fine-tuning bert for text classification in pytorch](https://luv-bansal.medium.com/fine-tuning-bert-for-text-classification-in-pytorch-503d97342db2)\n",
    "\n",
    "4. [pytorch sentiment classification github](https://github.com/clairett/pytorch-sentiment-classification/tree/master/data/SST2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUQDOmLDeMPo"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "\n",
    "MX_LENGTH = 50\n",
    "BATCH_SIZE = 32\n",
    "MASK_RATIO = 0.2\n",
    "EPOCHS = 3\n",
    "learning_rate = 5e-3 #5e-5 -> loss: 1~2 after one epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYOw7wn8_YIi"
   },
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Fp3gP2nfTga"
   },
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, tokenizer, max_length=512, mask_ratio=0.15):\n",
    "        super(BertDataset, self).__init__()\n",
    "        # self.root_dir='./data'\n",
    "        self.train_csv=pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
    "        self.tokenizer=tokenizer\n",
    "        self.target=self.train_csv.iloc[:,1]\n",
    "        self.max_length = max_length\n",
    "        self.mask_ratio = mask_ratio\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_csv)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(text=self.train_csv.iloc[index,0],\n",
    "                                            padding='max_length',\n",
    "                                            truncation=True,\n",
    "                                            add_special_tokens=True,\n",
    "                                            return_tensors='pt',\n",
    "                                            max_length=self.max_length,)\n",
    "\n",
    "        return {'input_ids': inputs[\"input_ids\"].clone().detach(),\n",
    "                'token_type_ids': inputs[\"token_type_ids\"].clone().detach(),}\n",
    "\n",
    "    def _apply_masking(self, x):\n",
    "        rand = torch.rand(x['input_ids'].shape)\n",
    "        mask = (rand < self.mask_ratio) * (x['input_ids'] != 101) * (x['input_ids'] != 102) * (x['input_ids'] != 0) # t/f tensor\n",
    "\n",
    "        selection = torch.flatten(mask[0].nonzero()).tolist() # idxs masked\n",
    "        x['input_ids'][0, selection] = 103 # apply MASK token\n",
    "\n",
    "        return x\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        batch={'input_ids':None, 'labels':None}\n",
    "        \n",
    "        # copy ids\n",
    "        tmp = [item['input_ids'] for item in data]\n",
    "        batch['labels'] = torch.stack(tmp).squeeze(1)\n",
    "        \n",
    "        # create mask tensor\n",
    "        data = list(map(self._apply_masking, data))\n",
    "        tmp = [item['input_ids'] for item in data]\n",
    "        batch['input_ids'] = torch.stack(tmp).squeeze(1)\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXoIN3AgAlnb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# dataset\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset= BertDataset(tokenizer, max_length=MX_LENGTH, mask_ratio=MASK_RATIO)\n",
    "\n",
    "# dataloader\n",
    "dataloader=DataLoader(dataset=dataset,batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "128XnwZsiZoD"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "###### Explore Dataset ######\n",
    "#############################\n",
    "\n",
    "for i, batch_data in enumerate(dataloader):\n",
    "    if i==0:\n",
    "        print(\"data shape\")\n",
    "        print(batch_data['labels'].shape) # batch_size * max_length\n",
    "        print()\n",
    "        print(\"before masking\")\n",
    "        print(batch_data['labels'][0]) # 101: CLS, 102: SEP / we use single sentence for fine-tuning task\n",
    "        print()\n",
    "        print(\"after masking (MASK = 103)\")\n",
    "        print(batch_data['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbAF5GNP_a3h"
   },
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9xtPgQlh_y4"
   },
   "outputs": [],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbmqvJeriX95"
   },
   "outputs": [],
   "source": [
    "for i, batch_data in enumerate(dataloader):\n",
    "    if i==0:\n",
    "        print(model(**batch_data).loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5TYnU7D_p_J"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OC9pa0_QxYvA"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 243368,
     "status": "ok",
     "timestamp": 1654580649024,
     "user": {
      "displayName": "­유은이 / 학생 / 데이터사이언스학과",
      "userId": "13602239954273849034"
     },
     "user_tz": -540
    },
    "id": "o8yVp0yjy1j0",
    "outputId": "50d02762-f78a-4a2a-d6d9-6f511cd4a174"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 217/217 [01:21<00:00,  2.66it/s, loss=4.86]\n",
      "Epoch 1: 100%|██████████| 217/217 [01:20<00:00,  2.68it/s, loss=4.74]\n",
      "Epoch 2: 100%|██████████| 217/217 [01:20<00:00,  2.68it/s, loss=4.72]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxusA873CoGz"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data = np.array(((1,1),(2,3),(3,4),(-0.5,-0.5), (-1,-2),(-2,-3),( -3,-4),(-4,-3)))\n",
    "label = np.array((1,1,1,-1,-1,-1,-1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data[:3,0],data[:3,1])\n",
    "plt.scatter(data[3:,0],data[3:,1])\n",
    "haha = np.linspace(-3,3)\n",
    "plt.plot(haha,-haha)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(theta, theta_0, data, label):\n",
    "    for i,x in enumerate(data):\n",
    "        if label[i]*(theta@x + theta_0) <= 0:\n",
    "            theta = theta+label[i]*x\n",
    "            theta_0 = theta_0 + label[i]\n",
    "    return theta, theta_0        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.5, 1.5]), 0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.array([0,0])\n",
    "theta_0 = 0\n",
    "perceptron(theta, theta_0, data, label) #data[:4], label[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = (np.array([[0.5,-np.sqrt(3)/2],[np.sqrt(3)/2,0.5]]) @ data.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f9ce0b62fa0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(transformed_data[:3,0],transformed_data[:3,1])\n",
    "plt.scatter(transformed_data[3:,0],transformed_data[3:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.54903811,  2.04903811]), 0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta =  np.array([0,0])\n",
    "theta_0 = 0\n",
    "perceptron(theta, theta_0, transformed_data, label) #data[:4], label[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.54903811,  2.04903811]), 0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron(theta, theta_0, transformed_data, label) #data[:4], label[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.59807621,  3.23205081])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3660254 ,  1.3660254 ],\n",
       "       [-1.59807621,  3.23205081],\n",
       "       [-1.96410162,  4.59807621],\n",
       "       [ 0.1830127 , -0.6830127 ],\n",
       "       [ 1.23205081, -1.8660254 ],\n",
       "       [ 1.59807621, -3.23205081],\n",
       "       [ 1.96410162, -4.59807621],\n",
       "       [ 0.59807621, -4.96410162]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3660254037844386"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5+np.sqrt(3)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.5, 1.5]), 0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron(theta, theta_0, data, label) #data[:4], label[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, -1, -1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(theta,  data, label):\n",
    "    for i,x in enumerate(data):\n",
    "        if label[i]*(theta@x) <= 0:\n",
    "            theta = theta+label[i]*x\n",
    "            #theta_0 = theta_0 + label[i]\n",
    "            print(\"haha\")\n",
    "    return theta       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.array([1,5])\n",
    "perceptron(theta,  data, label) #data[:4], label[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron(theta,  data, label) #data[:4], label[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPoGK5zfBeU8t4DtSM/Vsr/",
   "collapsed_sections": [
    "EDxtMC2g66gQ",
    "5PgCsIyawXoN",
    "8TqutY58tG-h",
    "aFDRFkQTC3YQ",
    "m3jkpgL7C7-_",
    "Tvzu6ONF2TyE",
    "siPUPEFXEbrD",
    "ZDma7XS2eKSQ",
    "SYOw7wn8_YIi",
    "xbAF5GNP_a3h",
    "g5TYnU7D_p_J"
   ],
   "name": "lab4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

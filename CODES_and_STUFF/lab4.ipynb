{"cells":[{"cell_type":"markdown","metadata":{"id":"EDxtMC2g66gQ"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4709,"status":"ok","timestamp":1654573242891,"user":{"displayName":"­유은이 / 학생 / 데이터사이언스학과","userId":"13602239954273849034"},"user_tz":-540},"id":"vj2CXov7JJqq","outputId":"f3feaad3-1cd6-409c-afbe-7acca4bdb037"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcKp4bZiJwut"},"outputs":[],"source":["%cd 'your_drive'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UHKo6dP6eEO6"},"outputs":[],"source":["!pip install transformers\n","import math\n","import pickle\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","import pandas as pd\n","import numpy as np\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OOnSsL1EeG85"},"outputs":[],"source":["SEED = 1111\n","\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{"id":"5PgCsIyawXoN"},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Lvt4lGJIe8i"},"outputs":[],"source":["from pathlib import Path\n","import sys\n","sys.path.insert(0,str(Path().absolute().joinpath(\"data\")))\n","from data import prepareData\n","import random\n","random.seed(SEED)\n","from torch.utils.data import random_split\n","\n","SOS_token = 0\n","EOS_token = 1\n","\n","MAX_LENGTH = 10\n","\n","TRAIN_RATIO = 0.6\n","VALID_RATIO = 0.2\n","\n","# BATCH_SIZE = 64\n","BATCH_SIZE = 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fePBsU2GKoaI"},"outputs":[],"source":["class TranslateDataset(Dataset):\n","    def __init__(self, max_length=10, fra2eng=True):\n","        self.input_lang, self.output_lang, self.pairs = prepareData('eng', 'fra', max_length=max_length, reverse=fra2eng)\n","        self.max_length=max_length\n","\n","        self.input_lang.addWord('PAD')\n","        self.output_lang.addWord('PAD')\n","        self.input_lang_pad = self.input_lang.word2index['PAD']\n","        self.output_lang_pad = self.output_lang.word2index['PAD']\n","        \n","        print(\"data example\")\n","        print(random.choice(self.pairs))\n","\n","    def __len__(self):\n","        return len(self.pairs)\n","\n","    def __getitem__(self, idx):\n","        pair = self.pairs[idx]\n","        x, y = self._tensorsFromPair(pair)\n","        return x, y\n","\n","    def _tensorFromSentence(self, lang, sentence):\n","        indexes = [lang.word2index[word] for word in sentence.split(' ')]\n","        indexes.append(EOS_token)\n","        return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n","\n","    def _tensorsFromPair(self, pair):\n","        input_tensor = self._tensorFromSentence(self.input_lang, pair[0])\n","        target_tensor = self._tensorFromSentence(self.output_lang, pair[1])\n","        return (input_tensor, target_tensor)\n","    \n","    def collate_fn(self, data):\n","        x_batch = []; y_batch = []\n","        \n","        for x, y in data:\n","            if x.shape[0] < self.max_length-1:\n","                x = torch.cat([x, self.input_lang_pad*torch.ones((self.max_length-1 - x.shape[0], 1), dtype=x.dtype)])\n","            elif x.shape[0] > self.max_length-1:\n","                x = x[:self.max_length-1]\n","            if y.shape[0] < self.max_length-1:\n","                y = torch.cat([y, self.output_lang_pad*torch.ones((self.max_length-1 - y.shape[0], 1), dtype=y.dtype)])\n","            elif y.shape[0] > self.max_length-1:\n","                y = y[:self.max_length-1]\n","\n","            x_batch.append(torch.cat([torch.tensor([SOS_token]), x.squeeze(1)]))\n","            y_batch.append(torch.cat([torch.tensor([SOS_token]), y.squeeze(1)]))\n","        \n","        return torch.stack(x_batch), torch.stack(y_batch)\n","\n","dataset = TranslateDataset(max_length=MAX_LENGTH)\n","\n","train_size = int(len(dataset)*TRAIN_RATIO)\n","valid_size = int(len(dataset)*VALID_RATIO)\n","train_data, valid_data, test_data = random_split(dataset, [train_size, valid_size, len(dataset)-(train_size+valid_size)],)\n","\n","train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n","valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n","test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)"]},{"cell_type":"code","source":["sample_x, sample_y = next(iter(train_dataloader))\n","sample_x = sample_x.squeeze(0)\n","sample_y = sample_y.squeeze(0)\n","\n","print(\"Sample sentences\\n\")\n","print(\"sample_x: \", sample_x)\n","print(' '.join([dataset.input_lang.index2word[i] for i in sample_x.tolist()]))\n","print(\"sample_y: \", sample_y)\n","print(' '.join([dataset.output_lang.index2word[i] for i in sample_y.tolist()]))"],"metadata":{"id":"z6lIHD3Xf6Ik"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8TqutY58tG-h"},"source":["# 1. Seq2seq model with Attention Mechanism"]},{"cell_type":"code","source":["#############################\n","##### Initialize Model ######\n","#############################\n","\n","in_dim =  # french\n","out_dim =  # english\n","\n","emb_dim =  # embbeding size\n","hid_dim =  # vector size of encoder output\n","\n","print(f'\\nin_dim: {in_dim}\\tout_dim: {out_dim}\\temb_dim: {emb_dim}\\thid_dim: {hid_dim}\\n')"],"metadata":{"id":"rgIpHf60hRfY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aFDRFkQTC3YQ"},"source":["## Encoder"]},{"cell_type":"code","source":["#############################\n","####### Prepare Input ####### \n","#############################\n","\n","print('Encoder Embedding outputs')\n","\n","embedded_x = nn.Embedding(in_dim, emb_dim)(sample_x)\n","print(embedded_x.shape)"],"metadata":{"id":"EbSJB9B-jl-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Initialize hidden and cell states')\n","\n","hidden_0 =  # (1, Hout) for unbatched input\n","cell_0 =  # (1, Hcell) for unbatched input"],"metadata":{"id":"MEH1RRbe1DrA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#############################\n","### Get output of Encoder ###\n","#############################\n"," \n","lstm = nn.LSTM(input_size=emb_dim, hidden_size=hid_dim)\n","hiddens, (hidden, cell) = lstm(embedded_x, (hidden_0, cell_0))\n","# hiddens = lstm(embedded_x, (hidden_0, cell_0))\n","\n","print('LSTM Encoder outputs')\n","print(f'hiddens: {hiddens.shape}\\thidden: {hidden.shape}\\tcell: {cell.shape}')\n","\n","enc_hiddens = hiddens # assign encoder outputs for decoder(w/attention, see below)"],"metadata":{"id":"XveBtVbhkMWp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# torch.sum(hiddens[-1]-hidden) # last value of hiddens = hidden"],"metadata":{"id":"iZhSxF7Kk89l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m3jkpgL7C7-_"},"source":["## Decoder"]},{"cell_type":"code","source":["#############################\n","###### Prepare Output ####### \n","#############################\n","\n","print('Decoder Embedding outputs')\n","\n","dec_embedder = nn.Embedding(out_dim, emb_dim)\n","embedded_y = dec_embedder(sample_y) # ground truth\n","print(embedded_y.shape)"],"metadata":{"id":"kdho8e70mV6h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#############################\n","####### Prepare Input ####### \n","#############################\n","\n","cell_0 = torch.zeros(1, hid_dim)\n","\n","input = embedded_y[0] # [SOS]\n","enc_output = hiddens[-1] # hidden\n","hidden = enc_output.unsqueeze(0)\n","cell = cell_0"],"metadata":{"id":"FHABukOMpY6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#############################\n","### Get output of Decoder ###\n","#############################\n","\n","seq2seq_outputs = []\n","decoder = nn.LSTM(input_size=emb_dim+hid_dim, hidden_size=hid_dim)\n","fc = nn.Linear(hid_dim, out_dim)\n","\n","for t in range(MAX_LENGTH):\n","\n","    input_encout_concat = torch.concat([input, enc_output])\n","    \n","    hiddens, (hidden, cell) = decoder(input_encout_concat.unsqueeze(0), (hidden, cell))\n","    \n","    next_token_idx = F.softmax(fc(hidden)).max(1)[1]\n","    \n","    seq2seq_outputs.append(hiddens)\n","    \n","\n","    # Update inputs for the next loop\n","    \n","    input = dec_embedder(next_token_idx).squeeze(0)\n","    # hidden = hidden\n","    # cell = cell\n","\n","\n","\n","    if t==0: \n","        print(f'input_encout_concat: {input_encout_concat.shape}')\n","        print('\\nLSTM Decoder outputs')\n","        print(f'hiddens: {hiddens.shape}\\thidden: {hidden.shape}\\tcell: {cell.shape}')\n","    "],"metadata":{"id":"l81Du2A-20uI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seq2seq_outputs = torch.stack(seq2seq_outputs)\n","seq2seq_outputs.shape # predicted"],"metadata":{"id":"shLkhz5mv8TT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Attention"],"metadata":{"id":"Tvzu6ONF2TyE"}},{"cell_type":"code","source":["#############################\n","## Set key/value and query ##\n","#############################\n","\n","# key, value\n","kv = enc_hiddens\n","print(\"Key/value shape:\\t\",  kv.shape)\n","\n","# query\n","example_t = 4 # any int [0 ~ MAX_LENGTH-1]\n","q = seq2seq_outputs[example_t]\n","print(\"Query shape:\\t\",  q.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DrmqlFUAw4b7","executionInfo":{"status":"ok","timestamp":1654570133314,"user_tz":-540,"elapsed":618,"user":{"displayName":"­유은이 / 학생 / 데이터사이언스학과","userId":"13602239954273849034"}},"outputId":"b212a92f-6e70-4a12-c738-58192aebf3b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Key/value shape:\t torch.Size([10, 512])\n","Query shape:\t torch.Size([1, 512])\n"]}]},{"cell_type":"code","source":["#############################\n","#### Get attention value ####\n","#############################\n","\n","attn_score =  #(10, 1)\n","\n","attn_coefficient =  #(10, 1)\n","\n","weighted_kv = kv*attn_coefficient\n","weighted_sum = torch.sum(weighted_kv, dim=0) # attention value\n","\n","print(\"attn_score shape:\\t\",  attn_score.shape)\n","print(\"weights: \\t\", attn_coefficient.squeeze(1).tolist())\n","print(\"total of weights: \\t\", sum(attn_coefficient.squeeze(1).tolist()))\n","print(\"weighted sum of val:\\t\", weighted_kv.shape)\n","print(\"weighted sum:\\t\", weighted_sum.shape)"],"metadata":{"id":"lSsUqg_8x4y-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654570293580,"user_tz":-540,"elapsed":327,"user":{"displayName":"­유은이 / 학생 / 데이터사이언스학과","userId":"13602239954273849034"}},"outputId":"14f07d04-7151-4549-e3a0-172dae9255b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["attn_score shape:\t torch.Size([10, 1])\n","weights: \t [0.06483325362205505, 0.09662076085805893, 0.10265860706567764, 0.09185811132192612, 0.06566578149795532, 0.089730404317379, 0.1004531979560852, 0.1402510553598404, 0.10215922445058823, 0.14576959609985352]\n","total of weights: \t 0.9999999925494194\n","weighted sum of val:\t torch.Size([10, 512])\n","weighted sum:\t torch.Size([512])\n"]}]},{"cell_type":"code","source":["sample_idx = 4  # which index of encoder output to attend [0~9]\n","\n","print(\"before attn\")\n","print(sum(kv[sample_idx]))\n","print(\"attn weight\")\n","print(attn_coefficient[sample_idx])\n","print(\"after attn\")\n","print(sum(weighted_kv[sample_idx]))"],"metadata":{"id":"Mh495Oi1zwyP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654573944008,"user_tz":-540,"elapsed":3,"user":{"displayName":"­유은이 / 학생 / 데이터사이언스학과","userId":"13602239954273849034"}},"outputId":"8a786094-8138-45ce-e41d-5fae4437d507"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["before attn\n","tensor(-0.9780, grad_fn=<AddBackward0>)\n","attn weight\n","tensor([0.0657], grad_fn=<SelectBackward0>)\n","after attn\n","tensor(-0.0642, grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"markdown","source":["# 2. Seq2seq model with Transformer"],"metadata":{"id":"siPUPEFXEbrD"}},{"cell_type":"code","source":["in_dim = dataset.input_lang.n_words\n","out_dim = dataset.output_lang.n_words\n","emb_dim = 256"],"metadata":{"id":"F5yc8iJ9GFrJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#############################\n","########### Input ########### \n","#############################\n","\n","embedded_x = nn.Embedding(in_dim, emb_dim)(sample_x)\n","print(\"embedded_x:\\t\", embedded_x.shape)"],"metadata":{"id":"SZw7whv9GSdY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Positional Encoding\n","1. Absolute sinusoid-based Positional Encoding\n","2. Relative Positional Encoding\n","3. Learnable Embedding (using nn.Embedding)"],"metadata":{"id":"sz_9Y4Q9Ecrt"}},{"cell_type":"code","source":["#############################\n","##### Position Encoding #####\n","#############################\n","\n","import matplotlib.pyplot as plt\n","\n","# Learnable\n","# pos = torch.arange(MAX_LENGTH).unsqueeze(1)\n","# pos_embedding = nn.Embedding(in_dim, emb_dim)(pos)\n","# plt.pcolormesh(pos_embedding.squeeze(1).detach().numpy(), cmap='RdBu') # Learnable\n","\n","# Absolute\n","with open('absolute_pe.pickle', 'rb') as handle:\n","    pe = pickle.load(handle)\n","plt.pcolormesh(pe.squeeze(1), cmap='RdBu')\n","\n","\n","plt.xlim((0, emb_dim))\n","plt.ylabel('Position')\n","plt.colorbar()\n","plt.show()\n"],"metadata":{"id":"xIg5RLUzEXQc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedded_pos = embedded_x + pe.squeeze(1)\n","print(\"embedded_pos:\\t\",embedded_pos.shape)"],"metadata":{"id":"aiLvHDrm9MC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#############################\n","##### src * trg masking #####\n","#############################\n","\n","# source masking\n","sample_x_mask = (sample_x == dataset.input_lang_pad)\n","\n","print(\"source mask = pad masking\")\n","print(sample_x_mask.squeeze().tolist())\n","\n","# target masking\n","pad_mask_neg = (sample_y != dataset.output_lang_pad).unsqueeze(1).unsqueeze(2)\n","sub_mask = torch.tril(torch.ones((MAX_LENGTH, MAX_LENGTH))).bool()\n","sample_y_mask = pad_mask_neg.permute(2,1,0) & sub_mask.unsqueeze(0)\n","\n","print(\"\\ntarget mask = pad masking + subsequent masking\")\n","print(pad_mask_neg.squeeze().tolist())\n","print()\n","print(sub_mask.squeeze())\n","print()\n","print(sample_y_mask.squeeze())"],"metadata":{"id":"GBizStE9POJR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#############################\n","########### Model ########### \n","#############################\n","\n","from torch.nn import Transformer\n","\n","hid_dim = emb_dim\n","ff_dim = 1024\n","n_heads = 8\n","n_enc_layers = 3\n","n_dec_layers = 5\n","dropout_p = 0.1\n","\n","class TransSeq2Seq(nn.Module):\n","    \n","    def __init__(self, hid_dim, ff_dim, n_heads, n_enc_layers, n_dec_layers, dropout_p):\n","        super().__init__()\n","        self.input_emb = nn.Embedding(in_dim, hid_dim)\n","        self.output_emb = nn.Embedding(out_dim, hid_dim)\n","        self.pos_emb = nn.Embedding(MAX_LENGTH, hid_dim)\n","\n","        self.transformer = Transformer(d_model=hid_dim,\n","                                       nhead=n_heads,\n","                                       num_encoder_layers=n_enc_layers,\n","                                       num_decoder_layers=n_dec_layers,\n","                                       dim_feedforward = ff_dim,\n","                                       dropout = dropout_p,\n","                                       activation = 'gelu')\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","    def forward(self, src, trg):\n","        \n","        embedded_pos = self.pos_emb(torch.arange(MAX_LENGTH).unsqueeze(1))\n","        embedded_x = self.input_emb(src)\n","        embedded_y = self.output_emb(trg)\n","\n","        embedded_x = self.dropout(torch.sum(embedded_x + embedded_pos, dim=1))\n","        embedded_y = self.dropout(torch.sum(embedded_y + embedded_pos, dim=1))\n","\n","        return self.transformer(embedded_x, embedded_y)\n","\n"],"metadata":{"id":"h-NgAbGqIFco"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TransSeq2Seq(hid_dim, ff_dim, n_heads, n_enc_layers, n_dec_layers, dropout_p)\n","print(model)"],"metadata":{"id":"EljQjKn0JYkc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["out = model(sample_x, sample_y)\n","print(out.shape)"],"metadata":{"id":"3no_Y49MPA7_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZDma7XS2eKSQ"},"source":["# 3. Bert fine-tuning"]},{"cell_type":"markdown","metadata":{"id":"WaKMY_DfUDmC"},"source":["ref.\n","\n","1. [huggingface BERT documentation](https://huggingface.co/transformers/v3.0.2/model_doc/bert.html#bert)\n","\n","2. [masked language modelling with bert](https://towardsdatascience.com/masked-language-modelling-with-bert-7d49793e5d2c)\n","\n","3. [fine-tuning bert for text classification in pytorch](https://luv-bansal.medium.com/fine-tuning-bert-for-text-classification-in-pytorch-503d97342db2)\n","\n","4. [pytorch sentiment classification github](https://github.com/clairett/pytorch-sentiment-classification/tree/master/data/SST2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gUQDOmLDeMPo"},"outputs":[],"source":["from transformers import BertTokenizer, BertForMaskedLM\n","from tqdm import tqdm\n","from torch.optim import AdamW\n","\n","MX_LENGTH = 50\n","BATCH_SIZE = 32\n","MASK_RATIO = 0.2\n","EPOCHS = 3\n","learning_rate = 5e-3 #5e-5 -> loss: 1~2 after one epoch"]},{"cell_type":"markdown","metadata":{"id":"SYOw7wn8_YIi"},"source":["## Prepare dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Fp3gP2nfTga"},"outputs":[],"source":["class BertDataset(Dataset):\n","    def __init__(self, tokenizer, max_length=512, mask_ratio=0.15):\n","        super(BertDataset, self).__init__()\n","        # self.root_dir='./data'\n","        self.train_csv=pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n","        self.tokenizer=tokenizer\n","        self.target=self.train_csv.iloc[:,1]\n","        self.max_length = max_length\n","        self.mask_ratio = mask_ratio\n","\n","    def __len__(self):\n","        return len(self.train_csv)\n","    \n","    def __getitem__(self, index):\n","        \n","        inputs = self.tokenizer.encode_plus(text=self.train_csv.iloc[index,0],\n","                                            padding='max_length',\n","                                            truncation=True,\n","                                            add_special_tokens=True,\n","                                            return_tensors='pt',\n","                                            max_length=self.max_length,)\n","\n","        return {'input_ids': inputs[\"input_ids\"].clone().detach(),\n","                'token_type_ids': inputs[\"token_type_ids\"].clone().detach(),}\n","\n","    def _apply_masking(self, x):\n","        rand = torch.rand(x['input_ids'].shape)\n","        mask = (rand < self.mask_ratio) * (x['input_ids'] != 101) * (x['input_ids'] != 102) * (x['input_ids'] != 0) # t/f tensor\n","\n","        selection = torch.flatten(mask[0].nonzero()).tolist() # idxs masked\n","        x['input_ids'][0, selection] = 103 # apply MASK token\n","\n","        return x\n","\n","    def collate_fn(self, data):\n","        batch={'input_ids':None, 'labels':None}\n","        \n","        # copy ids\n","        tmp = [item['input_ids'] for item in data]\n","        batch['labels'] = torch.stack(tmp).squeeze(1)\n","        \n","        # create mask tensor\n","        data = list(map(self._apply_masking, data))\n","        tmp = [item['input_ids'] for item in data]\n","        batch['input_ids'] = torch.stack(tmp).squeeze(1)\n","\n","        return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jXoIN3AgAlnb"},"outputs":[],"source":["\n","# dataset\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","dataset= BertDataset(tokenizer, max_length=MX_LENGTH, mask_ratio=MASK_RATIO)\n","\n","# dataloader\n","dataloader=DataLoader(dataset=dataset,batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"128XnwZsiZoD"},"outputs":[],"source":["#############################\n","###### Explore Dataset ######\n","#############################\n","\n","for i, batch_data in enumerate(dataloader):\n","    if i==0:\n","        print(\"data shape\")\n","        print(batch_data['labels'].shape) # batch_size * max_length\n","        print()\n","        print(\"before masking\")\n","        print(batch_data['labels'][0]) # 101: CLS, 102: SEP / we use single sentence for fine-tuning task\n","        print()\n","        print(\"after masking (MASK = 103)\")\n","        print(batch_data['input_ids'][0])"]},{"cell_type":"markdown","metadata":{"id":"xbAF5GNP_a3h"},"source":["## Prepare model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9xtPgQlh_y4"},"outputs":[],"source":["model = BertForMaskedLM.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbmqvJeriX95"},"outputs":[],"source":["for i, batch_data in enumerate(dataloader):\n","    if i==0:\n","        print(model(**batch_data).loss)"]},{"cell_type":"markdown","metadata":{"id":"g5TYnU7D_p_J"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OC9pa0_QxYvA"},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","model.train()\n","optim = AdamW(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243368,"status":"ok","timestamp":1654580649024,"user":{"displayName":"­유은이 / 학생 / 데이터사이언스학과","userId":"13602239954273849034"},"user_tz":-540},"id":"o8yVp0yjy1j0","outputId":"50d02762-f78a-4a2a-d6d9-6f511cd4a174"},"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 0: 100%|██████████| 217/217 [01:21<00:00,  2.66it/s, loss=4.86]\n","Epoch 1: 100%|██████████| 217/217 [01:20<00:00,  2.68it/s, loss=4.74]\n","Epoch 2: 100%|██████████| 217/217 [01:20<00:00,  2.68it/s, loss=4.72]\n"]}],"source":["for epoch in range(EPOCHS):\n","    loop = tqdm(dataloader, leave=True)\n","    for batch in loop:\n","        optim.zero_grad()\n","        \n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","        \n","        outputs = model(input_ids, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optim.step()\n","\n","        loop.set_description(f'Epoch {epoch}')\n","        loop.set_postfix(loss=loss.item())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OxusA873CoGz"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":["EDxtMC2g66gQ","5PgCsIyawXoN","8TqutY58tG-h","aFDRFkQTC3YQ","m3jkpgL7C7-_","Tvzu6ONF2TyE","siPUPEFXEbrD","ZDma7XS2eKSQ","SYOw7wn8_YIi","xbAF5GNP_a3h","g5TYnU7D_p_J"],"name":"lab4.ipynb","provenance":[],"authorship_tag":"ABX9TyPoGK5zfBeU8t4DtSM/Vsr/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
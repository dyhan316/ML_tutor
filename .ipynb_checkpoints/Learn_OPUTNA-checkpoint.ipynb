{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63491ab6-04ee-4243-b866-ecd30fea2296",
   "metadata": {},
   "source": [
    "### Optuna Tutorial 1 : \n",
    "https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/001_first.html#sphx-glr-tutorial-10-key-features-001-first-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ceaa4964-916b-4d4e-b9ac-9d99cf4c54b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float('x', -3,3) #add parameter to optimize \n",
    "    return (x-2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "919366cc-4f55-4cdd-8e25-10334f2466bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-15 07:00:05,858]\u001b[0m A new study created in memory with name: no-name-f73a5d9c-0dbe-4a65-9ea4-a7d24e1e3f36\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,864]\u001b[0m Trial 0 finished with value: 5.5384787646308 and parameters: {'x': -0.35339728151257965}. Best is trial 0 with value: 5.5384787646308.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,866]\u001b[0m Trial 1 finished with value: 4.444712417093395 and parameters: {'x': -0.1082486611150486}. Best is trial 1 with value: 4.444712417093395.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,869]\u001b[0m Trial 2 finished with value: 9.677057981205461 and parameters: {'x': -1.1107970009638142}. Best is trial 1 with value: 4.444712417093395.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,870]\u001b[0m Trial 3 finished with value: 1.9823178178378598 and parameters: {'x': 0.5920519122361578}. Best is trial 3 with value: 1.9823178178378598.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,872]\u001b[0m Trial 4 finished with value: 0.01086616640462463 and parameters: {'x': 2.1042409056207045}. Best is trial 4 with value: 0.01086616640462463.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,873]\u001b[0m Trial 5 finished with value: 15.519944954942396 and parameters: {'x': -1.9395361344887287}. Best is trial 4 with value: 0.01086616640462463.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,875]\u001b[0m Trial 6 finished with value: 13.513060646753042 and parameters: {'x': -1.6760115134141027}. Best is trial 4 with value: 0.01086616640462463.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,876]\u001b[0m Trial 7 finished with value: 7.637416878002142 and parameters: {'x': -0.7635876823437577}. Best is trial 4 with value: 0.01086616640462463.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,878]\u001b[0m Trial 8 finished with value: 0.4654956930739501 and parameters: {'x': 1.3177275521655956}. Best is trial 4 with value: 0.01086616640462463.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,880]\u001b[0m Trial 9 finished with value: 6.69520789264535 and parameters: {'x': -0.5875099792358967}. Best is trial 4 with value: 0.01086616640462463.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,885]\u001b[0m Trial 10 finished with value: 0.582977873764585 and parameters: {'x': 2.7635298774537804}. Best is trial 4 with value: 0.01086616640462463.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,890]\u001b[0m Trial 11 finished with value: 0.0073372094729629925 and parameters: {'x': 1.9143424873524628}. Best is trial 11 with value: 0.0073372094729629925.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,893]\u001b[0m Trial 12 finished with value: 0.4589982556466222 and parameters: {'x': 2.677494100082519}. Best is trial 11 with value: 0.0073372094729629925.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,897]\u001b[0m Trial 13 finished with value: 0.40140307825060734 and parameters: {'x': 1.3664362082231913}. Best is trial 11 with value: 0.0073372094729629925.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,900]\u001b[0m Trial 14 finished with value: 0.007768993905573338 and parameters: {'x': 1.9118581035739908}. Best is trial 11 with value: 0.0073372094729629925.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,902]\u001b[0m Trial 15 finished with value: 1.180553837717049 and parameters: {'x': 0.9134670563130406}. Best is trial 11 with value: 0.0073372094729629925.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,905]\u001b[0m Trial 16 finished with value: 24.457920001800165 and parameters: {'x': -2.9454949198032914}. Best is trial 11 with value: 0.0073372094729629925.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,908]\u001b[0m Trial 17 finished with value: 0.0037754625443843877 and parameters: {'x': 1.9385552073452568}. Best is trial 17 with value: 0.0037754625443843877.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,910]\u001b[0m Trial 18 finished with value: 2.7809841972171965 and parameters: {'x': 0.332371684931802}. Best is trial 17 with value: 0.0037754625443843877.\u001b[0m\n",
      "\u001b[32m[I 2022-12-15 07:00:05,913]\u001b[0m Trial 19 finished with value: 0.02432586038946403 and parameters: {'x': 2.15596749786242}. Best is trial 17 with value: 0.0037754625443843877.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "##creating the study and actually running it \n",
    "\"\"\"\n",
    "ftrial : single execution of the objective function\n",
    "\n",
    "\"\"\"\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f72adaf-8993-40fa-ae46-a463600b4e5d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 1.9385552073452568}\n",
      "0.0037754625443843877\n",
      "FrozenTrial(number=17, values=[0.0037754625443843877], datetime_start=datetime.datetime(2022, 12, 15, 7, 0, 5, 906325), datetime_complete=datetime.datetime(2022, 12, 15, 7, 0, 5, 907975), params={'x': 1.9385552073452568}, distributions={'x': UniformDistribution(high=3.0, low=-3.0)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=17, state=TrialState.COMPLETE, value=None)\n",
      "    number      value             datetime_start          datetime_complete  \\\n",
      "0        0   5.538479 2022-12-15 07:00:05.862921 2022-12-15 07:00:05.864158   \n",
      "1        1   4.444712 2022-12-15 07:00:05.866012 2022-12-15 07:00:05.866575   \n",
      "2        2   9.677058 2022-12-15 07:00:05.868254 2022-12-15 07:00:05.868696   \n",
      "3        3   1.982318 2022-12-15 07:00:05.870024 2022-12-15 07:00:05.870450   \n",
      "4        4   0.010866 2022-12-15 07:00:05.871569 2022-12-15 07:00:05.872018   \n",
      "5        5  15.519945 2022-12-15 07:00:05.873141 2022-12-15 07:00:05.873544   \n",
      "6        6  13.513061 2022-12-15 07:00:05.874645 2022-12-15 07:00:05.875052   \n",
      "7        7   7.637417 2022-12-15 07:00:05.876208 2022-12-15 07:00:05.876629   \n",
      "8        8   0.465496 2022-12-15 07:00:05.877762 2022-12-15 07:00:05.878159   \n",
      "9        9   6.695208 2022-12-15 07:00:05.880041 2022-12-15 07:00:05.880444   \n",
      "10      10   0.582978 2022-12-15 07:00:05.881670 2022-12-15 07:00:05.884873   \n",
      "11      11   0.007337 2022-12-15 07:00:05.886049 2022-12-15 07:00:05.890054   \n",
      "12      12   0.458998 2022-12-15 07:00:05.891172 2022-12-15 07:00:05.893508   \n",
      "13      13   0.401403 2022-12-15 07:00:05.894644 2022-12-15 07:00:05.897038   \n",
      "14      14   0.007769 2022-12-15 07:00:05.898110 2022-12-15 07:00:05.900038   \n",
      "15      15   1.180554 2022-12-15 07:00:05.900934 2022-12-15 07:00:05.902663   \n",
      "16      16  24.457920 2022-12-15 07:00:05.903773 2022-12-15 07:00:05.905469   \n",
      "17      17   0.003775 2022-12-15 07:00:05.906325 2022-12-15 07:00:05.907975   \n",
      "18      18   2.780984 2022-12-15 07:00:05.908964 2022-12-15 07:00:05.910309   \n",
      "19      19   0.024326 2022-12-15 07:00:05.911474 2022-12-15 07:00:05.913157   \n",
      "\n",
      "                 duration  params_x     state  \n",
      "0  0 days 00:00:00.001237 -0.353397  COMPLETE  \n",
      "1  0 days 00:00:00.000563 -0.108249  COMPLETE  \n",
      "2  0 days 00:00:00.000442 -1.110797  COMPLETE  \n",
      "3  0 days 00:00:00.000426  0.592052  COMPLETE  \n",
      "4  0 days 00:00:00.000449  2.104241  COMPLETE  \n",
      "5  0 days 00:00:00.000403 -1.939536  COMPLETE  \n",
      "6  0 days 00:00:00.000407 -1.676012  COMPLETE  \n",
      "7  0 days 00:00:00.000421 -0.763588  COMPLETE  \n",
      "8  0 days 00:00:00.000397  1.317728  COMPLETE  \n",
      "9  0 days 00:00:00.000403 -0.587510  COMPLETE  \n",
      "10 0 days 00:00:00.003203  2.763530  COMPLETE  \n",
      "11 0 days 00:00:00.004005  1.914342  COMPLETE  \n",
      "12 0 days 00:00:00.002336  2.677494  COMPLETE  \n",
      "13 0 days 00:00:00.002394  1.366436  COMPLETE  \n",
      "14 0 days 00:00:00.001928  1.911858  COMPLETE  \n",
      "15 0 days 00:00:00.001729  0.913467  COMPLETE  \n",
      "16 0 days 00:00:00.001696 -2.945495  COMPLETE  \n",
      "17 0 days 00:00:00.001650  1.938555  COMPLETE  \n",
      "18 0 days 00:00:00.001345  0.332372  COMPLETE  \n",
      "19 0 days 00:00:00.001683  2.155967  COMPLETE  \n"
     ]
    }
   ],
   "source": [
    "##looking at results \n",
    "\n",
    "print(study.best_params)\n",
    "\n",
    "print(study.best_value)\n",
    "\n",
    "print(study.best_trial)\n",
    "\n",
    "print(study.trials_dataframe()) #get all trials as dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae6af8-ab88-43b6-bb28-4396d765baff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea8419da-8594-435e-ab0e-c50ad8f6efe9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optuna Tutorial 2 : \n",
    "https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/002_configurations.html\n",
    "https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_simple.py\n",
    "https://www.youtube.com/watch?v=P6NwZVl8ttc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e695e5c-fc9a-4cc6-9e18-a9fb6629e58c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2-0. 공통\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fe9e6e-c1e0-48fa-9cdb-6ae6346890ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74f04e43-1faf-40de-9dd1-6233f1372434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the dataloader dataset \n",
    "def get_mnist(batch_size):\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(os.getcwd(), train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72bbeb6-5035-46de-a5fc-81213f9c1afa",
   "metadata": {},
   "source": [
    "### 2-1. Without Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "512422c2-ca60-434a-a720-207599f04dad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0 training loss, : 1.44558846950531\n",
      "EPOCH : 0 validation loss, accuracy : 1.2670201063156128 / 0.5609375\n",
      "EPOCH : 1 training loss, : 1.2591526508331299\n",
      "EPOCH : 1 validation loss, accuracy : 1.0117079019546509 / 0.6578125\n",
      "EPOCH : 2 training loss, : 1.1057322025299072\n",
      "EPOCH : 2 validation loss, accuracy : 0.986359715461731 / 0.6828125\n",
      "EPOCH : 3 training loss, : 1.3560160398483276\n",
      "EPOCH : 3 validation loss, accuracy : 0.9358760118484497 / 0.703125\n",
      "EPOCH : 4 training loss, : 1.24252450466156\n",
      "EPOCH : 4 validation loss, accuracy : 0.7710863947868347 / 0.7625\n",
      "EPOCH : 5 training loss, : 1.2464555501937866\n",
      "EPOCH : 5 validation loss, accuracy : 0.7817651033401489 / 0.8078125\n",
      "EPOCH : 6 training loss, : 1.2980538606643677\n",
      "EPOCH : 6 validation loss, accuracy : 0.8685086965560913 / 0.7015625\n",
      "EPOCH : 7 training loss, : 1.2039804458618164\n",
      "EPOCH : 7 validation loss, accuracy : 1.006385087966919 / 0.715625\n",
      "EPOCH : 8 training loss, : 1.152542233467102\n",
      "EPOCH : 8 validation loss, accuracy : 0.8106120228767395 / 0.725\n",
      "EPOCH : 9 training loss, : 1.277761697769165\n",
      "EPOCH : 9 validation loss, accuracy : 0.738945722579956 / 0.746875\n"
     ]
    }
   ],
   "source": [
    "#hardcoding my hyperparameters in \n",
    "DEVICE = torch.device(0)\n",
    "class my_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_model, self).__init__()\n",
    "        #parameters to be optimized later\n",
    "        self.n_layers = 3 #will be optimized later\n",
    "        \n",
    "        layers = []\n",
    "        in_features = 28*28  #input featues, for first layer is the img size flattened\n",
    "        #use for loop to create model \n",
    "        for i in range(self.n_layers):\n",
    "            #parameters to be optimized later\n",
    "            out_features = 64 \n",
    "            dropout_rate = 0.5\n",
    "            \n",
    "            layers.append(nn.Linear(in_features, out_features))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate)) \n",
    "            \n",
    "            in_features = out_features #so that it it is used proerly in next iteration\n",
    "        \n",
    "        layers.append(nn.Linear(in_features, 10)) #classificaiton layer\n",
    "        layers.append(nn.LogSoftmax(dim = 1 )) #classification, normalize using softmax\n",
    "        self.total = nn.Sequential(*layers) #create model \n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.total(x) \n",
    "    \n",
    "    \"\"\"\n",
    "    parameters to be optimized if using optuna\n",
    "    * self.n_layers\n",
    "    * out_features (for each layer)\n",
    "    * dropout_rate \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "###runing the actual modde\n",
    "model = my_model().to(DEVICE)\n",
    "\n",
    "\n",
    "##parameters to be optimized\n",
    "lr = 1e-2\n",
    "BATCHSIZE = 64\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "\n",
    "train_loader, valid_loader = get_mnist(batch_size = BATCHSIZE )\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    \n",
    "    #get training loss \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #limiting training dataset for faster epochs (일단은 무시)\n",
    "        if batch_idx*BATCHSIZE > BATCHSIZE*30 :  #i.e. don't do many iterations (only a few per epoch)\n",
    "            break\n",
    "        \n",
    "        #doing some stuff to data\n",
    "        data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE) \n",
    "        \n",
    "        #actual training\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "    print(f\"EPOCH : {epoch} training loss, : {loss.item()}\")\n",
    "    #get valdiation loss\n",
    "    model.eval()\n",
    "    correct = 0 #count number of correct samples, to get accruacy\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "            #limiting validation size \n",
    "            if batch_idx*BATCHSIZE > BATCHSIZE*10 : \n",
    "                break\n",
    "            \n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE) \n",
    "            \n",
    "            #actual validaiton \n",
    "            output = model(data)\n",
    "            # Get the index of the max log-probability.\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            \n",
    "            \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "    accuracy = correct / min(len(valid_loader.dataset), BATCHSIZE*10) \n",
    "        \n",
    "    print(f\"EPOCH : {epoch} validation loss, accuracy : {loss} / {accuracy}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f161d984-7b2d-4914-bb68-508f5769dd50",
   "metadata": {},
   "source": [
    "### 2-2. With Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52df29fc-9ad6-43e1-ad2f-74f00f757097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "#hardcoding my hyperparameters in \n",
    "DEVICE = torch.device(0)\n",
    "\n",
    "##model takes in trial as input \n",
    "class my_model(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "        super(my_model, self).__init__()\n",
    "        #parameters to be optimized later\n",
    "        self.n_layers = trial.suggest_int(name = \"n_layers\", low =1, high = 3) \n",
    "        \n",
    "        layers = []\n",
    "        in_features = 28*28  #input featues, for first layer is the img size flattened\n",
    "        #use for loop to create model \n",
    "        for i in range(self.n_layers):\n",
    "            #parameters to be optimized later\n",
    "            #out_features = 64 \n",
    "            out_features = trial.suggest_int(f\"n_units_l{i}\", 4, 64)\n",
    "            #dropout_rate = 0.5\n",
    "            dropout_rate = trial.suggest_float(f\"dropout_l{i}\", 0.00001, 0.5)\n",
    "            \n",
    "            layers.append(nn.Linear(in_features, out_features))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate)) \n",
    "            \n",
    "            in_features = out_features #so that it it is used proerly in next iteration\n",
    "        \n",
    "        layers.append(nn.Linear(in_features, 10)) #classificaiton layer\n",
    "        layers.append(nn.LogSoftmax(dim = 1 )) #classification, normalize using softmax\n",
    "        self.total = nn.Sequential(*layers) #create model \n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.total(x) \n",
    "    \n",
    "    \"\"\"\n",
    "    parameters to be optimized if using optuna\n",
    "    * self.n_layers\n",
    "    * out_features (for each layer)\n",
    "    * dropout_rate \n",
    "    \"\"\"                     \n",
    "    \n",
    "\n",
    "def objective(trial):\n",
    "    ###runing the actual modde\n",
    "    #model = my_model().to(DEVICE)\n",
    "    model = my_model(trial).to(DEVICE) #must put trial in \n",
    "    \n",
    "    \n",
    "    ##parameters to be optimized\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log = True)\n",
    "    BATCHSIZE = trial.suggest_int(\"batch_size\", 16, 128, log = True)\n",
    "    optimizer_choice = trial.suggest_categorical('optimizer', [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "\n",
    "    \n",
    "    #using the trial suggest things and use them to define our wanted things\n",
    "    optimizer = getattr(optim, optimizer_choice)(model.parameters(), lr = lr) \n",
    "    train_loader, valid_loader = get_mnist(batch_size = BATCHSIZE )\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        \n",
    "        #get training loss \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            #limiting training dataset for faster epochs (일단은 무시)\n",
    "            if batch_idx*BATCHSIZE > BATCHSIZE*30 :  #i.e. don't do many iterations (only a few per epoch)\n",
    "                break\n",
    "            \n",
    "            #doing some stuff to data\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE) \n",
    "            \n",
    "            #actual training\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "        print(f\"EPOCH : {epoch} training loss, : {loss.item()}\")\n",
    "        #get valdiation loss\n",
    "        model.eval()\n",
    "        correct = 0 #count number of correct samples, to get accruacy\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                #limiting validation size \n",
    "                if batch_idx*BATCHSIZE > BATCHSIZE*10 : \n",
    "                    break\n",
    "                \n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE) \n",
    "                \n",
    "                #actual validaiton \n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                \n",
    "                \n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "        accuracy = correct / min(len(valid_loader.dataset), BATCHSIZE*10) \n",
    "        \n",
    "        trial.report(accuracy, epoch)\n",
    "            \n",
    "        print(f\"EPOCH : {epoch} validation loss, accuracy : {loss} / {accuracy}\") \n",
    "        \n",
    "    return accuracy #the final thing we want to maximize \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "906731da-23d2-4ce9-b667-dc2bc3e9cfa8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-15 08:13:02,080]\u001b[0m A new study created in memory with name: no-name-bc0e523b-03cd-4371-bee9-5c06ad655840\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0 training loss, : 2.3051068782806396\n",
      "EPOCH : 0 validation loss, accuracy : 2.2711310386657715 / 0.14347826086956522\n",
      "EPOCH : 1 training loss, : 2.30908203125\n",
      "EPOCH : 1 validation loss, accuracy : 2.313206911087036 / 0.15217391304347827\n",
      "EPOCH : 2 training loss, : 2.326399803161621\n",
      "EPOCH : 2 validation loss, accuracy : 2.307403564453125 / 0.11304347826086956\n",
      "EPOCH : 3 training loss, : 2.249756097793579\n",
      "EPOCH : 3 validation loss, accuracy : 2.3247530460357666 / 0.11304347826086956\n",
      "EPOCH : 4 training loss, : 2.3093459606170654\n",
      "EPOCH : 4 validation loss, accuracy : 2.297776699066162 / 0.10869565217391304\n",
      "EPOCH : 5 training loss, : 2.312589645385742\n",
      "EPOCH : 5 validation loss, accuracy : 2.3328182697296143 / 0.1\n",
      "EPOCH : 6 training loss, : 2.336906909942627\n",
      "EPOCH : 6 validation loss, accuracy : 2.3381197452545166 / 0.11304347826086956\n",
      "EPOCH : 7 training loss, : 2.308753252029419\n",
      "EPOCH : 7 validation loss, accuracy : 2.3415067195892334 / 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-15 08:13:04,009]\u001b[0m Trial 0 finished with value: 0.10434782608695652 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.17855996046819958, 'learning_rate': 0.08900813792059299, 'batch_size': 23, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.10434782608695652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 8 training loss, : 2.2986466884613037\n",
      "EPOCH : 8 validation loss, accuracy : 2.275066614151001 / 0.1\n",
      "EPOCH : 9 training loss, : 2.3049588203430176\n",
      "EPOCH : 9 validation loss, accuracy : 2.2854137420654297 / 0.10434782608695652\n",
      "EPOCH : 0 training loss, : 1.6498234272003174\n",
      "EPOCH : 0 validation loss, accuracy : 1.4582188129425049 / 0.37894736842105264\n",
      "EPOCH : 1 training loss, : 1.5474704504013062\n",
      "EPOCH : 1 validation loss, accuracy : 1.3117706775665283 / 0.55\n",
      "EPOCH : 2 training loss, : 2.0586979389190674\n",
      "EPOCH : 2 validation loss, accuracy : 1.3011032342910767 / 0.5210526315789473\n",
      "EPOCH : 3 training loss, : 1.7187128067016602\n",
      "EPOCH : 3 validation loss, accuracy : 1.3362942934036255 / 0.5289473684210526\n",
      "EPOCH : 4 training loss, : 2.475966691970825\n",
      "EPOCH : 4 validation loss, accuracy : 1.1579374074935913 / 0.5605263157894737\n",
      "EPOCH : 5 training loss, : 1.5992028713226318\n",
      "EPOCH : 5 validation loss, accuracy : 1.3074030876159668 / 0.5\n",
      "EPOCH : 6 training loss, : 1.579829454421997\n",
      "EPOCH : 6 validation loss, accuracy : 1.291825771331787 / 0.5368421052631579\n",
      "EPOCH : 7 training loss, : 1.7671926021575928\n",
      "EPOCH : 7 validation loss, accuracy : 1.3375200033187866 / 0.49736842105263157\n",
      "EPOCH : 8 training loss, : 1.791581630706787\n",
      "EPOCH : 8 validation loss, accuracy : 0.9829880595207214 / 0.5447368421052632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-15 08:13:06,695]\u001b[0m Trial 1 finished with value: 0.5447368421052632 and parameters: {'n_layers': 2, 'n_units_l0': 25, 'dropout_l0': 0.2909773299760975, 'n_units_l1': 33, 'dropout_l1': 0.27700146118102575, 'learning_rate': 0.039969510756996396, 'batch_size': 38, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.5447368421052632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 9 training loss, : 1.4360685348510742\n",
      "EPOCH : 9 validation loss, accuracy : 1.2510637044906616 / 0.5447368421052632\n",
      "EPOCH : 0 training loss, : 1.4154343605041504\n",
      "EPOCH : 0 validation loss, accuracy : 1.3569728136062622 / 0.6625\n",
      "EPOCH : 1 training loss, : 1.0157678127288818\n",
      "EPOCH : 1 validation loss, accuracy : 0.9199507236480713 / 0.7041666666666667\n",
      "EPOCH : 2 training loss, : 0.9514319896697998\n",
      "EPOCH : 2 validation loss, accuracy : 0.8064494729042053 / 0.7083333333333334\n",
      "EPOCH : 3 training loss, : 0.9848077297210693\n",
      "EPOCH : 3 validation loss, accuracy : 0.8776698708534241 / 0.76875\n",
      "EPOCH : 4 training loss, : 0.9569882750511169\n",
      "EPOCH : 4 validation loss, accuracy : 0.938585102558136 / 0.7645833333333333\n",
      "EPOCH : 5 training loss, : 0.6795335412025452\n",
      "EPOCH : 5 validation loss, accuracy : 0.9946942925453186 / 0.7291666666666666\n",
      "EPOCH : 6 training loss, : 0.4675517976284027\n",
      "EPOCH : 6 validation loss, accuracy : 0.6545667052268982 / 0.7666666666666667\n",
      "EPOCH : 7 training loss, : 0.7728875279426575\n",
      "EPOCH : 7 validation loss, accuracy : 0.9846453070640564 / 0.79375\n",
      "EPOCH : 8 training loss, : 0.890066921710968\n",
      "EPOCH : 8 validation loss, accuracy : 0.7382405400276184 / 0.7916666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-15 08:13:09,766]\u001b[0m Trial 2 finished with value: 0.825 and parameters: {'n_layers': 1, 'n_units_l0': 55, 'dropout_l0': 0.31399781832384477, 'learning_rate': 0.08908825191422877, 'batch_size': 48, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 9 training loss, : 0.8450053334236145\n",
      "EPOCH : 9 validation loss, accuracy : 0.881669282913208 / 0.825\n",
      "EPOCH : 0 training loss, : 0.7708604335784912\n",
      "EPOCH : 0 validation loss, accuracy : 1.0173569917678833 / 0.7\n",
      "EPOCH : 1 training loss, : 0.8704533576965332\n",
      "EPOCH : 1 validation loss, accuracy : 0.7490975856781006 / 0.7886075949367088\n",
      "EPOCH : 2 training loss, : 0.6956444382667542\n",
      "EPOCH : 2 validation loss, accuracy : 0.6840141415596008 / 0.8253164556962025\n",
      "EPOCH : 3 training loss, : 0.6921578049659729\n",
      "EPOCH : 3 validation loss, accuracy : 0.6946635842323303 / 0.8493670886075949\n",
      "EPOCH : 4 training loss, : 0.5818004608154297\n",
      "EPOCH : 4 validation loss, accuracy : 0.7994970679283142 / 0.8620253164556962\n",
      "EPOCH : 5 training loss, : 0.6955828666687012\n",
      "EPOCH : 5 validation loss, accuracy : 0.5565395355224609 / 0.8810126582278481\n",
      "EPOCH : 6 training loss, : 0.6561560034751892\n",
      "EPOCH : 6 validation loss, accuracy : 0.6620483994483948 / 0.8810126582278481\n",
      "EPOCH : 7 training loss, : 0.6262658834457397\n",
      "EPOCH : 7 validation loss, accuracy : 0.514004111289978 / 0.8531645569620253\n",
      "EPOCH : 8 training loss, : 0.36884644627571106\n",
      "EPOCH : 8 validation loss, accuracy : 0.5861636996269226 / 0.910126582278481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-15 08:13:13,887]\u001b[0m Trial 3 finished with value: 0.910126582278481 and parameters: {'n_layers': 2, 'n_units_l0': 47, 'dropout_l0': 0.053321589361190976, 'n_units_l1': 42, 'dropout_l1': 0.12176002475279113, 'learning_rate': 0.0039108232529245, 'batch_size': 79, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.910126582278481.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 9 training loss, : 0.43540337681770325\n",
      "EPOCH : 9 validation loss, accuracy : 0.5448771715164185 / 0.910126582278481\n",
      "EPOCH : 0 training loss, : 2.2914047241210938\n",
      "EPOCH : 0 validation loss, accuracy : 2.2889881134033203 / 0.11553398058252427\n",
      "EPOCH : 1 training loss, : 2.307521104812622\n",
      "EPOCH : 1 validation loss, accuracy : 2.3002734184265137 / 0.10485436893203884\n",
      "EPOCH : 2 training loss, : 2.2987911701202393\n",
      "EPOCH : 2 validation loss, accuracy : 2.3012588024139404 / 0.11844660194174757\n",
      "EPOCH : 3 training loss, : 2.2739646434783936\n",
      "EPOCH : 3 validation loss, accuracy : 2.280863046646118 / 0.11844660194174757\n",
      "EPOCH : 4 training loss, : 2.294856309890747\n",
      "EPOCH : 4 validation loss, accuracy : 2.279388904571533 / 0.1407766990291262\n",
      "EPOCH : 5 training loss, : 2.2863621711730957\n",
      "EPOCH : 5 validation loss, accuracy : 2.2813262939453125 / 0.13980582524271845\n",
      "EPOCH : 6 training loss, : 2.282925844192505\n",
      "EPOCH : 6 validation loss, accuracy : 2.285648822784424 / 0.15922330097087378\n",
      "EPOCH : 7 training loss, : 2.274698495864868\n",
      "EPOCH : 7 validation loss, accuracy : 2.2702178955078125 / 0.18640776699029127\n",
      "EPOCH : 8 training loss, : 2.2768442630767822\n",
      "EPOCH : 8 validation loss, accuracy : 2.282731533050537 / 0.1912621359223301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-15 08:13:18,715]\u001b[0m Trial 4 finished with value: 0.1883495145631068 and parameters: {'n_layers': 2, 'n_units_l0': 25, 'dropout_l0': 0.21694181157711775, 'n_units_l1': 50, 'dropout_l1': 0.007226884231549922, 'learning_rate': 0.0016217838257004881, 'batch_size': 103, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.910126582278481.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 9 training loss, : 2.271996021270752\n",
      "EPOCH : 9 validation loss, accuracy : 2.27305269241333 / 0.1883495145631068\n",
      "EPOCH : 0 training loss, : 2.3289425373077393\n",
      "EPOCH : 0 validation loss, accuracy : 2.297908306121826 / 0.115\n",
      "EPOCH : 1 training loss, : 2.3118555545806885\n",
      "EPOCH : 1 validation loss, accuracy : 2.302295207977295 / 0.09\n",
      "EPOCH : 2 training loss, : 2.3677563667297363\n",
      "EPOCH : 2 validation loss, accuracy : 2.3357558250427246 / 0.175\n",
      "EPOCH : 3 training loss, : 2.3071701526641846\n",
      "EPOCH : 3 validation loss, accuracy : 2.331156015396118 / 0.095\n",
      "EPOCH : 4 training loss, : 2.3521523475646973\n",
      "EPOCH : 4 validation loss, accuracy : 2.339510917663574 / 0.14\n",
      "EPOCH : 5 training loss, : 2.321157693862915\n",
      "EPOCH : 5 validation loss, accuracy : 2.325172185897827 / 0.095\n",
      "EPOCH : 6 training loss, : 2.527195692062378\n",
      "EPOCH : 6 validation loss, accuracy : 2.3920693397521973 / 0.125\n",
      "EPOCH : 7 training loss, : 2.303990602493286\n",
      "EPOCH : 7 validation loss, accuracy : 2.331155300140381 / 0.09\n",
      "EPOCH : 8 training loss, : 2.289472818374634\n",
      "EPOCH : 8 validation loss, accuracy : 2.3328280448913574 / 0.14\n",
      "EPOCH : 9 training loss, : 2.325705051422119\n",
      "EPOCH : 9 validation loss, accuracy : 2.2684314250946045 / 0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-15 08:13:20,919]\u001b[0m Trial 5 finished with value: 0.105 and parameters: {'n_layers': 3, 'n_units_l0': 13, 'dropout_l0': 0.4243536923708754, 'n_units_l1': 22, 'dropout_l1': 0.31464836047414657, 'n_units_l2': 38, 'dropout_l2': 0.2930894742636657, 'learning_rate': 0.04369262826920034, 'batch_size': 20, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.910126582278481.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0 training loss, : 2.3362557888031006\n",
      "EPOCH : 0 validation loss, accuracy : 2.237962007522583 / 0.2064516129032258\n",
      "EPOCH : 1 training loss, : 2.2423083782196045\n",
      "EPOCH : 1 validation loss, accuracy : 2.2523646354675293 / 0.1870967741935484\n",
      "EPOCH : 2 training loss, : 2.3525803089141846\n",
      "EPOCH : 2 validation loss, accuracy : 2.3320677280426025 / 0.15806451612903225\n",
      "EPOCH : 3 training loss, : 2.1208791732788086\n",
      "EPOCH : 3 validation loss, accuracy : 2.171037197113037 / 0.24516129032258063\n",
      "EPOCH : 4 training loss, : 2.07279109954834\n",
      "EPOCH : 4 validation loss, accuracy : 2.1410229206085205 / 0.25483870967741934\n",
      "EPOCH : 5 training loss, : 2.1829607486724854\n",
      "EPOCH : 5 validation loss, accuracy : 1.9362494945526123 / 0.15806451612903225\n",
      "EPOCH : 6 training loss, : 1.9682570695877075\n",
      "EPOCH : 6 validation loss, accuracy : 2.1374261379241943 / 0.2903225806451613\n",
      "EPOCH : 7 training loss, : 2.2370150089263916\n",
      "EPOCH : 7 validation loss, accuracy : 1.9615991115570068 / 0.26129032258064516\n",
      "EPOCH : 8 training loss, : 2.1760904788970947\n",
      "EPOCH : 8 validation loss, accuracy : 2.2214395999908447 / 0.2129032258064516\n",
      "EPOCH : 9 training loss, : 2.158043622970581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-15 08:13:23,182]\u001b[0m Trial 6 finished with value: 0.24838709677419354 and parameters: {'n_layers': 2, 'n_units_l0': 19, 'dropout_l0': 0.1922479875544288, 'n_units_l1': 19, 'dropout_l1': 0.2378381347762606, 'learning_rate': 0.0629936351967956, 'batch_size': 31, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.910126582278481.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 9 validation loss, accuracy : 2.066653251647949 / 0.24838709677419354\n",
      "EPOCH : 0 training loss, : 2.3171188831329346\n",
      "EPOCH : 0 validation loss, accuracy : 2.313969850540161 / 0.11379310344827587\n",
      "EPOCH : 1 training loss, : 2.297602891921997\n",
      "EPOCH : 1 validation loss, accuracy : 2.3006694316864014 / 0.10114942528735632\n",
      "EPOCH : 2 training loss, : 2.2991764545440674\n",
      "EPOCH : 2 validation loss, accuracy : 2.3087055683135986 / 0.11954022988505747\n",
      "EPOCH : 3 training loss, : 2.302236318588257\n",
      "EPOCH : 3 validation loss, accuracy : 2.3015668392181396 / 0.11839080459770115\n",
      "EPOCH : 4 training loss, : 2.307239055633545\n",
      "EPOCH : 4 validation loss, accuracy : 2.3052656650543213 / 0.10689655172413794\n",
      "EPOCH : 5 training loss, : 2.3053483963012695\n",
      "EPOCH : 5 validation loss, accuracy : 2.3121609687805176 / 0.08735632183908046\n",
      "EPOCH : 6 training loss, : 2.2949182987213135\n",
      "EPOCH : 6 validation loss, accuracy : 2.3015642166137695 / 0.10689655172413794\n",
      "EPOCH : 7 training loss, : 2.304650068283081\n",
      "EPOCH : 7 validation loss, accuracy : 2.3068320751190186 / 0.11149425287356322\n",
      "EPOCH : 8 training loss, : 2.315423011779785\n",
      "EPOCH : 8 validation loss, accuracy : 2.301896333694458 / 0.11149425287356322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-15 08:13:27,624]\u001b[0m Trial 7 finished with value: 0.09195402298850575 and parameters: {'n_layers': 3, 'n_units_l0': 61, 'dropout_l0': 0.36053927560263316, 'n_units_l1': 58, 'dropout_l1': 0.4585038691827602, 'n_units_l2': 11, 'dropout_l2': 0.30766028560338166, 'learning_rate': 0.02112421264356082, 'batch_size': 87, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.910126582278481.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 9 training loss, : 2.2960150241851807\n",
      "EPOCH : 9 validation loss, accuracy : 2.3062727451324463 / 0.09195402298850575\n",
      "EPOCH : 0 training loss, : 0.7982692122459412\n",
      "EPOCH : 0 validation loss, accuracy : 0.7190901637077332 / 0.8209876543209876\n",
      "EPOCH : 1 training loss, : 0.5741562843322754\n",
      "EPOCH : 1 validation loss, accuracy : 0.6055198311805725 / 0.8530864197530864\n",
      "EPOCH : 2 training loss, : 0.48095476627349854\n",
      "EPOCH : 2 validation loss, accuracy : 0.6871677041053772 / 0.8827160493827161\n",
      "EPOCH : 3 training loss, : 0.49216723442077637\n",
      "EPOCH : 3 validation loss, accuracy : 0.6058894991874695 / 0.854320987654321\n",
      "EPOCH : 4 training loss, : 0.6380926966667175\n",
      "EPOCH : 4 validation loss, accuracy : 0.6824563145637512 / 0.8777777777777778\n",
      "EPOCH : 5 training loss, : 0.49605512619018555\n",
      "EPOCH : 5 validation loss, accuracy : 0.563435435295105 / 0.8839506172839506\n",
      "EPOCH : 6 training loss, : 0.6299576759338379\n",
      "EPOCH : 6 validation loss, accuracy : 0.5444654822349548 / 0.8765432098765432\n",
      "EPOCH : 7 training loss, : 0.4925781190395355\n",
      "EPOCH : 7 validation loss, accuracy : 0.4535115957260132 / 0.9358024691358025\n",
      "EPOCH : 8 training loss, : 0.35891610383987427\n",
      "EPOCH : 8 validation loss, accuracy : 0.48420989513397217 / 0.9074074074074074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-15 08:13:31,651]\u001b[0m Trial 8 finished with value: 0.9098765432098765 and parameters: {'n_layers': 1, 'n_units_l0': 33, 'dropout_l0': 0.051787921861834556, 'learning_rate': 0.007035245494009382, 'batch_size': 81, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.910126582278481.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 9 training loss, : 0.32724499702453613\n",
      "EPOCH : 9 validation loss, accuracy : 0.2949514091014862 / 0.9098765432098765\n",
      "EPOCH : 0 training loss, : 1.2016900777816772\n",
      "EPOCH : 0 validation loss, accuracy : 1.1662019491195679 / 0.6660377358490566\n",
      "EPOCH : 1 training loss, : 1.107042670249939\n",
      "EPOCH : 1 validation loss, accuracy : 0.950439453125 / 0.7622641509433963\n",
      "EPOCH : 2 training loss, : 1.0517178773880005\n",
      "EPOCH : 2 validation loss, accuracy : 0.7939538955688477 / 0.7528301886792453\n",
      "EPOCH : 3 training loss, : 0.8979871273040771\n",
      "EPOCH : 3 validation loss, accuracy : 0.6665497422218323 / 0.7735849056603774\n",
      "EPOCH : 4 training loss, : 0.8266420364379883\n",
      "EPOCH : 4 validation loss, accuracy : 0.8141704797744751 / 0.8018867924528302\n",
      "EPOCH : 5 training loss, : 0.9853619933128357\n",
      "EPOCH : 5 validation loss, accuracy : 0.6295116543769836 / 0.7754716981132076\n",
      "EPOCH : 6 training loss, : 0.9803934693336487\n",
      "EPOCH : 6 validation loss, accuracy : 0.6702020764350891 / 0.8226415094339623\n",
      "EPOCH : 7 training loss, : 0.8977094888687134\n",
      "EPOCH : 7 validation loss, accuracy : 0.8550135493278503 / 0.8566037735849057\n",
      "EPOCH : 8 training loss, : 0.8277719020843506\n",
      "EPOCH : 8 validation loss, accuracy : 0.5743646025657654 / 0.8150943396226416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-15 08:13:34,799]\u001b[0m Trial 9 finished with value: 0.8415094339622642 and parameters: {'n_layers': 1, 'n_units_l0': 36, 'dropout_l0': 0.3579131750257493, 'learning_rate': 0.0012738904784910588, 'batch_size': 53, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.910126582278481.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 9 training loss, : 0.9847554564476013\n",
      "EPOCH : 9 validation loss, accuracy : 0.5504941344261169 / 0.8415094339622642\n",
      "Study statistics: \n",
      "  Number of finished trials:  10\n",
      "Best trial:\n",
      "  Value:  0.910126582278481\n",
      "  Params: \n",
      "    n_layers: 2\n",
      "    n_units_l0: 47\n",
      "    dropout_l0: 0.053321589361190976\n",
      "    n_units_l1: 42\n",
      "    dropout_l1: 0.12176002475279113\n",
      "    learning_rate: 0.0039108232529245\n",
      "    batch_size: 79\n",
      "    optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "##actual pruning \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials= 10, timeout= 600)\n",
    "\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items(): #get dict values \n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34944f98-6ae2-453e-b699-5e7e1a5401c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "suggest_float() missing 4 required positional arguments: 'self', 'name', 'low', and 'high'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m optuna\u001b[38;5;241m.\u001b[39mtrial\u001b[38;5;241m.\u001b[39mTrial\u001b[38;5;241m.\u001b[39msuggest_int()\n",
      "\u001b[0;31mTypeError\u001b[0m: suggest_float() missing 4 required positional arguments: 'self', 'name', 'low', and 'high'"
     ]
    }
   ],
   "source": [
    "optuna.trial.Trial.suggest_float()\n",
    "optuna.trial.Trial.suggest_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a7920-61da-4bd2-adfe-e1c633d28986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bfba61-9775-49db-8e38-e05970b44f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df87136c-b438-4442-b7b6-adfdea21aee7",
   "metadata": {},
   "source": [
    "### Optuna CV\n",
    "https://stackoverflow.com/questions/63224426/how-can-i-cross-validate-by-pytorch-and-optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72697e-2fbe-407a-bc1a-c6825f6f40d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAE_3DCNN_older_MONAI",
   "language": "python",
   "name": "vae_3dcnn_older_monai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
